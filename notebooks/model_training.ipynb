{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\iNeuron\\\\Projects\\\\scania_failures_2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from src.config.configuration_manager import ConfigurationManager\n",
    "from src.components.stage_3_data_split import data_splitting_component\n",
    "from src.components.stage_4_final_preprocessing import stage_4_final_processing_component\n",
    "from src.utils import eval_metrics,save_yaml\n",
    "\n",
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\scania_failures_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-26 13:14:32,527: INFO: utils: config.yaml yaml_file is loaded]\n",
      "[2024-01-26 13:14:32,538: INFO: utils: params.yaml yaml_file is loaded]\n",
      "[2024-01-26 13:14:32,544: INFO: utils: schema.yaml yaml_file is loaded]\n"
     ]
    }
   ],
   "source": [
    "obj = ConfigurationManager()\n",
    "stage_1_obj = obj.get_stage1_processing_config()\n",
    "stage_2_obj = obj.get_stage2_processing_config()\n",
    "data_split_obj = obj.get_data_split_config()\n",
    "preprocessor_obj = obj.get_preprocessor_config()\n",
    "model_obj = obj.get_model_config()\n",
    "\n",
    "data_split_class_obj = data_splitting_component(data_split_conf = data_split_obj,\n",
    "                                                stage1_processor_conf = stage_1_obj)\n",
    "stage_4_final_processing_class_obj = stage_4_final_processing_component(data_split_conf = data_split_obj,\n",
    "                                                                        stage_2_processor_conf = stage_2_obj,\n",
    "                                                                        preprocessor_conf = preprocessor_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  None\n",
      "Pre_train_data shape:  (45000, 171) \n",
      "Pre_test_data shape:  (15000, 171)\n"
     ]
    }
   ],
   "source": [
    "train_data_training_set,train_data_testing_set = data_split_class_obj.data_splitting(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-26 11:58:41,485: INFO: utils: config.yaml yaml_file is loaded]\n",
      "[2024-01-26 11:58:41,489: INFO: utils: params.yaml yaml_file is loaded]\n",
      "[2024-01-26 11:58:41,493: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 11:58:41,497: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 11:58:41,499: INFO: utils: Stage 2 Processing Commencing]\n",
      "[2024-01-26 11:58:41,500: INFO: utils: Pipeline created with KnnImputer, RobustScaler]\n",
      "[2024-01-26 11:58:41,501: INFO: utils: SmoteTomek obj created]\n",
      "[2024-01-26 11:58:41,533: INFO: utils: Commencing pipeline transformation]\n",
      "[Pipeline] ....... (step 1 of 2) Processing Knn_imputer, total=16.4min\n",
      "[Pipeline] ..... (step 2 of 2) Processing Robust_Scaler, total=   0.3s\n",
      "[2024-01-26 12:15:02,498: INFO: utils: Pipeline transformation complete]\n",
      "[2024-01-26 12:15:02,503: INFO: utils: Commencing SmoteTomek]\n",
      "[2024-01-26 12:15:37,320: INFO: utils: SmoteTomek Complete]\n",
      "[2024-01-26 12:15:37,321: INFO: utils: Returning the transformed dataframe]\n",
      "[2024-01-26 12:15:37,334: INFO: utils: Saving the pipeline object]\n",
      "[2024-01-26 12:15:37,398: INFO: utils: object: artifacts/preprocessor/preprocessor.joblib pickled]\n",
      "[2024-01-26 12:15:37,400: INFO: utils: Pipeline saved at: artifacts/preprocessor/preprocessor.joblib]\n",
      "[2024-01-26 12:15:37,401: INFO: utils: Stage 2 Processing Complete]\n",
      "[2024-01-26 12:15:37,427: INFO: utils: config.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:15:37,432: INFO: utils: params.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:15:37,436: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:15:37,440: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:15:37,443: INFO: utils: Stage 2 Processing Commencing]\n",
      "[2024-01-26 12:15:37,504: INFO: utils: pickled_object: artifacts/preprocessor/preprocessor.joblib loaded]\n",
      "[2024-01-26 12:15:37,505: INFO: utils: Pipeline loaded & SmoteTomek created]\n",
      "[2024-01-26 12:15:37,557: INFO: utils: Commencing pipeline transformation]\n",
      "[2024-01-26 12:20:56,157: INFO: utils: Pipeline transformation complete]\n",
      "[2024-01-26 12:20:56,159: INFO: utils: Commencing SmoteTomek]\n",
      "[2024-01-26 12:21:00,194: INFO: utils: SmoteTomek Complete]\n",
      "[2024-01-26 12:21:00,195: INFO: utils: Returning the transformed dataframe]\n",
      "[2024-01-26 12:21:00,198: INFO: utils: Stage 2 Processing Complete]\n"
     ]
    }
   ],
   "source": [
    "transformed_train_df, transformed_test_df = stage_4_final_processing_class_obj.final_processing(train_data_training_set,\n",
    "                                                                                                train_data_testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88332, 171)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29406, 171)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_df.isna().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test_df.isna().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    44166\n",
       "1    44166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    14703\n",
       "1    14703\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.642451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.184510e-01</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513180</td>\n",
       "      <td>-0.473398</td>\n",
       "      <td>-0.472359</td>\n",
       "      <td>-0.341886</td>\n",
       "      <td>-0.246246</td>\n",
       "      <td>-0.028516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.647499</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-9.111617e-02</td>\n",
       "      <td>-0.336449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516161</td>\n",
       "      <td>-0.478466</td>\n",
       "      <td>-0.477442</td>\n",
       "      <td>-0.343247</td>\n",
       "      <td>-0.247308</td>\n",
       "      <td>-0.028962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.646405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.466970e-02</td>\n",
       "      <td>-0.205607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515376</td>\n",
       "      <td>-0.478164</td>\n",
       "      <td>-0.477356</td>\n",
       "      <td>-0.343320</td>\n",
       "      <td>-0.247344</td>\n",
       "      <td>-0.028962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.894240e-01</td>\n",
       "      <td>1.425234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657849</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.682807</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>-0.110265</td>\n",
       "      <td>-0.007890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.647204</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.386727e+06</td>\n",
       "      <td>-0.345794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516105</td>\n",
       "      <td>-0.478462</td>\n",
       "      <td>-0.477416</td>\n",
       "      <td>-0.343079</td>\n",
       "      <td>-0.245686</td>\n",
       "      <td>-0.028962</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aa_000  ab_000        ac_000    ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0 -0.642451     0.0 -1.184510e-01 -0.130841     0.0     0.0     0.0     0.0   \n",
       "1 -0.647499    -0.5 -9.111617e-02 -0.336449     0.0     0.0     0.0     0.0   \n",
       "2 -0.646405     0.0 -5.466970e-02 -0.205607     0.0     0.0     0.0     0.0   \n",
       "3  0.221708     0.0  4.894240e-01  1.425234     0.0     0.0     0.0     0.0   \n",
       "4 -0.647204    -0.5  1.386727e+06 -0.345794     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ag_003  ...    ee_003    ee_004    ee_005    ee_006    ee_007  \\\n",
       "0     0.0     0.0  ... -0.513180 -0.473398 -0.472359 -0.341886 -0.246246   \n",
       "1     0.0     0.0  ... -0.516161 -0.478466 -0.477442 -0.343247 -0.247308   \n",
       "2     0.0     0.0  ... -0.515376 -0.478164 -0.477356 -0.343320 -0.247344   \n",
       "3     0.0     0.0  ...  0.657849  0.963839  0.682807  0.064776 -0.110265   \n",
       "4     0.0     0.0  ... -0.516105 -0.478462 -0.477416 -0.343079 -0.245686   \n",
       "\n",
       "     ee_008    ee_009  ef_000  eg_000  class  \n",
       "0 -0.028516  0.000000     0.0     0.0      0  \n",
       "1 -0.028962  0.000000     0.0     0.0      0  \n",
       "2 -0.028962  0.000000     0.0     0.0      0  \n",
       "3 -0.007890  0.000000     0.0     0.0      0  \n",
       "4 -0.028962  0.089216     0.0     0.0      0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = transformed_train_df.drop(columns = 'class'),transformed_train_df['class']\n",
    "x_test, y_test = transformed_test_df.drop(columns = 'class'),transformed_test_df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model('file:artifacts/model/challenger_hyperopt_SGD_Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Balanced_Accuracy_Score': 0.6172209753111609,\n",
       " 'F1_Score': 0.6819260766361479,\n",
       " 'Accuracy_Score': 0.6172209753111609,\n",
       " 'Cost': 1404690.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "eval_metrics(y_true = y_test, \n",
    "             y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  1500\n",
      "Pre_train_data shape:  (1125, 171) \n",
      "Pre_test_data shape:  (375, 171)\n",
      "[2024-01-26 12:38:24,015: INFO: utils: config.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,020: INFO: utils: params.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,025: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,029: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,030: INFO: utils: Stage 2 Processing Commencing]\n",
      "[2024-01-26 12:38:24,031: INFO: utils: Pipeline created with KnnImputer, RobustScaler]\n",
      "[2024-01-26 12:38:24,033: INFO: utils: SmoteTomek obj created]\n",
      "[2024-01-26 12:38:24,035: INFO: utils: Commencing pipeline transformation]\n",
      "[Pipeline] ....... (step 1 of 2) Processing Knn_imputer, total=   0.5s\n",
      "[Pipeline] ..... (step 2 of 2) Processing Robust_Scaler, total=   0.0s\n",
      "[2024-01-26 12:38:24,528: INFO: utils: Pipeline transformation complete]\n",
      "[2024-01-26 12:38:24,530: INFO: utils: Commencing SmoteTomek]\n",
      "[2024-01-26 12:38:24,590: INFO: utils: SmoteTomek Complete]\n",
      "[2024-01-26 12:38:24,591: INFO: utils: Returning the transformed dataframe]\n",
      "[2024-01-26 12:38:24,593: INFO: utils: Saving the pipeline object]\n",
      "[2024-01-26 12:38:24,596: INFO: utils: object: artifacts/preprocessor/preprocessor.joblib pickled]\n",
      "[2024-01-26 12:38:24,597: INFO: utils: Pipeline saved at: artifacts/preprocessor/preprocessor.joblib]\n",
      "[2024-01-26 12:38:24,597: INFO: utils: Stage 2 Processing Complete]\n",
      "[2024-01-26 12:38:24,601: INFO: utils: config.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,606: INFO: utils: params.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,609: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,612: INFO: utils: schema.yaml yaml_file is loaded]\n",
      "[2024-01-26 12:38:24,613: INFO: utils: Stage 2 Processing Commencing]\n",
      "[2024-01-26 12:38:24,627: INFO: utils: pickled_object: artifacts/preprocessor/preprocessor.joblib loaded]\n",
      "[2024-01-26 12:38:24,627: INFO: utils: Pipeline loaded & SmoteTomek created]\n",
      "[2024-01-26 12:38:24,629: INFO: utils: Commencing pipeline transformation]\n",
      "[2024-01-26 12:38:24,807: INFO: utils: Pipeline transformation complete]\n",
      "[2024-01-26 12:38:24,808: INFO: utils: Commencing SmoteTomek]\n",
      "[2024-01-26 12:38:24,827: INFO: utils: SmoteTomek Complete]\n",
      "[2024-01-26 12:38:24,829: INFO: utils: Returning the transformed dataframe]\n",
      "[2024-01-26 12:38:24,831: INFO: utils: Stage 2 Processing Complete]\n"
     ]
    }
   ],
   "source": [
    "train_data_training_set_, train_data_testing_set_ = data_split_class_obj.data_splitting(1500)\n",
    "transformed_train_df_, transformed_test_df_ = stage_4_final_processing_class_obj.final_processing(train_data_training_set_,\n",
    "                                                                                                train_data_testing_set_)\n",
    "x_train_, y_train_ = transformed_train_df_.drop(columns = 'class'),transformed_train_df_['class']\n",
    "x_test_, y_test_ = transformed_test_df_.drop(columns = 'class'),transformed_test_df_['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Balanced_Accuracy_Score': 0.65,\n",
       " 'F1_Score': 0.7278617710583153,\n",
       " 'Accuracy_Score': 0.65,\n",
       " 'Cost': 13790.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ = model.predict(x_test_)\n",
    "eval_metrics(y_true = y_test_, \n",
    "             y_pred = y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3043be8b328d4809b8c693668da148ea'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metadata.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: challenger_hyperopt_SGD_Classifier\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 3043be8b328d4809b8c693668da148ea"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.load_model(f\"file:artifacts/model/hp_tuned_model/{model.metadata.artifact_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent subdirectory is: artifacts/model/hp_tuned_model/challenger_hyperopt_SGD_Classifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_most_recent_subdirectory(parent_directory):\n",
    "    # Get a list of all subdirectories in the parent directory\n",
    "    subdirectories = [d for d in os.listdir(parent_directory) if os.path.isdir(os.path.join(parent_directory, d))]\n",
    "\n",
    "    # If there are no subdirectories, return None\n",
    "    if not subdirectories:\n",
    "        return None\n",
    "\n",
    "    # Sort the subdirectories by modification time (most recent first)\n",
    "    subdirectories.sort(key=lambda d: os.path.getmtime(os.path.join(parent_directory, d)), reverse=True)\n",
    "\n",
    "    # Return the most recent subdirectory\n",
    "    return os.path.join(parent_directory, subdirectories[0])\n",
    "\n",
    "# Example usage:\n",
    "parent_directory = \"artifacts/model/hp_tuned_model/\"\n",
    "most_recent_subdirectory = get_most_recent_subdirectory(parent_directory)\n",
    "\n",
    "if most_recent_subdirectory:\n",
    "    print(f\"The most recent subdirectory is: {most_recent_subdirectory}\")\n",
    "else:\n",
    "    print(\"No subdirectories found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifacts/model'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'challenger_hyperopt_SGD_Classifier'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metadata.artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts\\\\model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124miNeuron\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mscania_failures_2\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124martifacts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43msave_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\ineuron\\projects\\scania_failures_2\\src\\utils.py:71\u001b[0m, in \u001b[0;36msave_yaml\u001b[1;34m(file, filepath)\u001b[0m\n\u001b[0;32m     69\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml file is saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mf:\\ineuron\\projects\\scania_failures_2\\src\\utils.py:67\u001b[0m, in \u001b[0;36msave_yaml\u001b[1;34m(file, filepath)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_yaml\u001b[39m(file,filepath:Path):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m         yaml\u001b[38;5;241m.\u001b[39mdump(data \u001b[38;5;241m=\u001b[39m file,\n\u001b[1;32m---> 67\u001b[0m                   stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     68\u001b[0m                   indent \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     69\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml file is saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts\\\\model'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "os.chdir(f\"F:\\iNeuron\\Projects\\scania_failures_2\\\\artifacts\\model\")\n",
    "save_yaml(file = model.metadata.artifact_path, filepath = Path(f\"{model_obj.root_dir}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\iNeuron\\\\Projects\\\\scania_failures_2'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
