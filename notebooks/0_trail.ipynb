{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "import yaml\n",
    "import ast\n",
    "import mlflow\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, \n",
    "                              HistGradientBoostingClassifier, StackingClassifier, VotingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (balanced_accuracy_score, f1_score,\n",
    "                             accuracy_score, confusion_matrix)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from src.constants import *\n",
    "from src.utils import load_yaml\n",
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\Scania_Truck_Failures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"\")\n",
    "registered_models = {}\n",
    "for i in range(len(mlflow.search_registered_models())):\n",
    "    registered_models[mlflow.search_registered_models()[i].latest_versions[0].name] = mlflow.search_registered_models()[i].latest_versions[0].run_id\n",
    "registered_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\iNeuron\\\\Projects\\\\Scania_Truck_Failures'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, {'clientId': 'test', 'secret': 'test', 'token': 'test'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "[0,json.loads('{\"clientId\": \"test\", \"secret\": \"test\", \"token\":\"test\"}')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student (Raj) scored 90.2 in Science\n"
     ]
    }
   ],
   "source": [
    "class greeting:\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 marks: float):\n",
    "        self.name = name\n",
    "        self.marks = marks\n",
    "    def greeting_function(self, *args):\n",
    "        if args:\n",
    "            self.subject = args[0]\n",
    "        else:\n",
    "            self.subject = \"Maths\"\n",
    "        print (f\"The student ({self.name}) scored {self.marks} in {self.subject}\")\n",
    "\n",
    "obj = greeting(name='Raj', marks=90.2)\n",
    "obj.greeting_function('Science')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking train_data, test_data values and sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33058.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60874.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0  76698.0     NaN  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1  33058.0     NaN  0.000000e+00     NaN     0.0     0.0     0.0     0.0   \n",
       "2  41040.0     NaN  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3     12.0     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4  60874.0     NaN  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ag_003  ...     ee_002    ee_003    ee_004    ee_005    ee_006  \\\n",
       "0     0.0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0   \n",
       "1     0.0     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   \n",
       "2     0.0     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0   \n",
       "3     0.0   318.0  ...      240.0      46.0      58.0      44.0      10.0   \n",
       "4     0.0     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0   \n",
       "\n",
       "     ee_007    ee_008  ee_009  ef_000  eg_000  \n",
       "0  157956.0   73224.0     0.0     0.0     0.0  \n",
       "1   81140.0   97576.0  1500.0     0.0     0.0  \n",
       "2  158022.0   95128.0   514.0     0.0     0.0  \n",
       "3       0.0       0.0     0.0     4.0    32.0  \n",
       "4  311560.0  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\iNeuron\\Projects\\scania_failures_2\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 170) (2500, 170) (7500,) (2500,)\n",
      "class\n",
      "0    7351\n",
      "1     149\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "0    2454\n",
      "1      46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:10000,:].drop(columns='class')\n",
    "y = df.iloc[:10000,:]['class']\n",
    "# skf = StratifiedKFold()\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.25, random_state=8)\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-27 13:30:35,746: INFO: utils: params.yaml yaml_file is loaded]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigBox({'optuna': {'Logistic_Regression': {'penalty': \"trial.suggest_categorical('penalty', ['l2', None])\"}, 'SGD_Classifier': {'loss': \"trial.suggest_categorical('loss', ['squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_error', 'perceptron', 'squared_hinge', 'hinge', 'log_loss', 'modified_huber'])\"}, 'Random Forest': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\", 'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Ada_Boost': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\", 'algorithm': \"trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R'])\"}, 'Grad_Boost': {'loss': \"trial.suggest_categorical('loss', ['log_loss', 'exponential'])\", 'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\", 'criterion': \"trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\"}, 'Bagging_Classifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\"}, 'ExtraTreesClassifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\", 'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Hist_Grad_Boost_Classifier': {'max_iter': \"trial.suggest_int('max_iter', 100, 800)\"}, 'Decision_Tree_Classifier': {'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'splitter': \"trial.suggest_categorical('splitter', ['best', 'random'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\"}, 'XGB_Classifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1000)\", 'learning_rate': \"trial.suggest_float('learning_rate', .00001, 8.0)\", 'booster': \"trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart'])\", 'tree_method': \"trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\"}, 'KNN_Classifier': {'n_neighbors': \"trial.suggest_int('n_neighbors', 3, 11, step=2)\", 'weights': \"trial.suggest_categorical('weights', ['uniform', 'distance'])\", 'algorithm': \"trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\"}, 'MLP_Classifier': {'hidden_layer_sizes': \"trial.suggest_categorical('hidden_layer_sizes', [(500,), (500, 300, 200, 150,), (700, 500, 300, 100, ), (1500, 800, 400, 200, )])\", 'activation': \"trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh' , 'relu'])\", 'learning_rate': \"trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive'])\", 'max_iter': \"trial.suggest_int('max_iter', 100, 800)\"}, 'Stacked_Classifier': {'stack_method': \"trial.suggest_categorical('stack_method', ['auto', 'predict'])\", 'passthrough': \"trial.suggest_categorical('passthrough', [True, False])\"}}, 'hyperopt': {'Logistic_Regression': {'penalty': \"hp.choice('penalty', ['l2', None])\"}, 'SGD_Classifier': {'loss': \"hp.choice('loss', ['squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_error', 'perceptron', 'squared_hinge', 'hinge', 'log_loss', 'modified_huber'])\"}, 'Random Forest': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\", 'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"hp.choice('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Ada_Boost': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\", 'algorithm': \"hp.choice('algorithm', ['SAMME', 'SAMME.R'])\"}, 'Grad_Boost': {'loss': \"hp.choice('loss', ['log_loss', 'exponential'])\", 'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\", 'criterion': \"hp.choice('criterion', ['friedman_mse', 'squared_error'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\"}, 'Bagging_Classifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\"}, 'ExtraTreesClassifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\", 'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"hp.choice('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Hist_Grad_Boost_Classifier': {'max_iter': \"scope.int(hp.quniform('max_iter', 100, 800, 1))\"}, 'Decision_Tree_Classifier': {'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'splitter': \"hp.choice('splitter', ['best', 'random'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\"}, 'XGB_Classifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1000, 1))\", 'learning_rate': \"hp.uniform('learning_rate', .00001, 8.0)\", 'booster': \"hp.choice('booster', ['gbtree', 'gblinear', 'dart'])\", 'tree_method': \"hp.choice('tree_method', ['exact', 'approx', 'hist'])\"}, 'KNN_Classifier': {'n_neighbors': \"scope.int(hp.quniform('n_neighbors', 3, 11, 2))\", 'weights': \"hp.choice('weights', ['uniform', 'distance'])\", 'algorithm': \"hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\"}, 'MLP_Classifier': {'hidden_layer_sizes': \"hp.choice('hidden_layer_sizes', [(500,), (500, 300, 200, 150,), (700, 500, 300, 100, ), (1500, 800, 400, 200, )])\", 'activation': \"hp.choice('activation', ['identity', 'logistic', 'tanh' , 'relu'])\", 'learning_rate': \"hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive'])\", 'max_iter': \"scope.int(hp.quniform('max_iter', 100, 800, 1))\"}, 'Stacked_Classifier': {'stack_method': \"hp.choice('stack_method', ['auto', 'predict'])\", 'passthrough': \"hp.choice('passthrough', [True, False])\"}}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_config = load_yaml(PARAMS_PATH)\n",
    "params_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BoxKeyError",
     "evalue": "\"'ConfigBox' object has no attribute 'randomized_search_cv'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:592\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'randomized_search_cv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:631\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:619\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'randomized_search_cv'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:633\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'randomized_search_cv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\config_box.py:29\u001b[0m, in \u001b[0;36mbox.config_box.ConfigBox.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:647\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'randomized_search_cv'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:592\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'randomized_search_cv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:631\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:619\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'randomized_search_cv'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:633\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'randomized_search_cv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mdict\u001b[39m(\u001b[43mparams_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandomized_search_cv\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\config_box.py:31\u001b[0m, in \u001b[0;36mbox.config_box.ConfigBox.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\box\\box.py:647\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'randomized_search_cv'\""
     ]
    }
   ],
   "source": [
    "dict(params_config.randomized_search_cv['Random Forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params.yaml', 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "while scanning a simple key\n  in \"config/config.yaml\", line 5, column 1\ncould not find expected ':'\n  in \"config/config.yaml\", line 6, column 26",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig/config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n\u001b[1;32m----> 3\u001b[0m     config_ \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43myaml_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m config_\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_load\u001b[39m(stream):\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\composer.py:64\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, index):\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAliasEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     65\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[0;32m     66\u001b[0m         anchor \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39manchor\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\parser.py:449\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(ValueToken):\n\u001b[0;32m    448\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeyToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValueToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBlockEndToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_mapping_key)\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_node_or_indentless_sequence()\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\scanner.py:115\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mchoices):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneed_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_more_tokens()\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\scanner.py:152\u001b[0m, in \u001b[0;36mScanner.need_more_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# The current token may be a potential simple key, so we\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# need to look further.\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstale_possible_simple_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_possible_simple_key() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens_taken:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\yaml\\scanner.py:291\u001b[0m, in \u001b[0;36mScanner.stale_possible_simple_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mline \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline  \\\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m-\u001b[39mkey\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1024\u001b[39m:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mrequired:\n\u001b[1;32m--> 291\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile scanning a simple key\u001b[39m\u001b[38;5;124m\"\u001b[39m, key\u001b[38;5;241m.\u001b[39mmark,\n\u001b[0;32m    292\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not find expected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_simple_keys[level]\n",
      "\u001b[1;31mScannerError\u001b[0m: while scanning a simple key\n  in \"config/config.yaml\", line 5, column 1\ncould not find expected ':'\n  in \"config/config.yaml\", line 6, column 26"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "with open('config/config.yaml') as yaml_file:\n",
    "    config_ = yaml.safe_load(yaml_file)\n",
    "config_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config['optuna']['Logistic_Regression']\n",
    "# space = {}\n",
    "# for key,value in config['optuna']['Random Forest'].items():\n",
    "#     space[key] = eval(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_splitter</th>\n",
       "      <th>state</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params_booster</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>params_algorithm</th>\n",
       "      <th>params_n_neighbors</th>\n",
       "      <th>params_weights</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985980</td>\n",
       "      <td>2024-01-31 08:30:03.809967</td>\n",
       "      <td>2024-01-31 08:34:43.396304</td>\n",
       "      <td>0 days 00:04:39.586337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Light_GBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.973820</td>\n",
       "      <td>2024-01-31 07:41:08.839523</td>\n",
       "      <td>2024-01-31 07:45:52.525983</td>\n",
       "      <td>0 days 00:04:43.686460</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.972720</td>\n",
       "      <td>2024-01-31 07:50:26.000225</td>\n",
       "      <td>2024-01-31 07:54:26.238470</td>\n",
       "      <td>0 days 00:04:00.238245</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>2024-01-31 07:45:52.528036</td>\n",
       "      <td>2024-01-31 07:50:25.997216</td>\n",
       "      <td>0 days 00:04:33.469180</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.955599</td>\n",
       "      <td>2024-01-31 08:16:20.304787</td>\n",
       "      <td>2024-01-31 08:21:35.162398</td>\n",
       "      <td>0 days 00:05:14.857611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>5.0</td>\n",
       "      <td>distance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>2024-01-31 08:10:57.771196</td>\n",
       "      <td>2024-01-31 08:16:20.301786</td>\n",
       "      <td>0 days 00:05:22.530590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>2024-01-31 08:21:35.163428</td>\n",
       "      <td>2024-01-31 08:26:45.061112</td>\n",
       "      <td>0 days 00:05:09.897684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value              datetime_start           datetime_complete  \\\n",
       "10       1  0.985980  2024-01-31 08:30:03.809967  2024-01-31 08:34:43.396304   \n",
       "0        0  0.973820  2024-01-31 07:41:08.839523  2024-01-31 07:45:52.525983   \n",
       "2        2  0.972720  2024-01-31 07:50:26.000225  2024-01-31 07:54:26.238470   \n",
       "1        1  0.969000  2024-01-31 07:45:52.528036  2024-01-31 07:50:25.997216   \n",
       "7        1  0.955599  2024-01-31 08:16:20.304787  2024-01-31 08:21:35.162398   \n",
       "6        0  0.944959  2024-01-31 08:10:57.771196  2024-01-31 08:16:20.301786   \n",
       "8        2  0.944959  2024-01-31 08:21:35.163428  2024-01-31 08:26:45.061112   \n",
       "\n",
       "                  duration params_criterion params_max_features  \\\n",
       "10  0 days 00:04:39.586337              NaN                 NaN   \n",
       "0   0 days 00:04:43.686460          entropy                log2   \n",
       "2   0 days 00:04:00.238245             gini                 NaN   \n",
       "1   0 days 00:04:33.469180         log_loss                log2   \n",
       "7   0 days 00:05:14.857611              NaN                 NaN   \n",
       "6   0 days 00:05:22.530590              NaN                 NaN   \n",
       "8   0 days 00:05:09.897684              NaN                 NaN   \n",
       "\n",
       "   params_splitter     state                Model_name params_booster  \\\n",
       "10             NaN  COMPLETE                 Light_GBM            NaN   \n",
       "0             best  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "2           random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "1           random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "7              NaN  COMPLETE            KNN_Classifier            NaN   \n",
       "6              NaN  COMPLETE            KNN_Classifier            NaN   \n",
       "8              NaN  COMPLETE            KNN_Classifier            NaN   \n",
       "\n",
       "    params_learning_rate  params_n_estimators params_tree_method  \\\n",
       "10              0.181309                121.0                NaN   \n",
       "0                    NaN                  NaN                NaN   \n",
       "2                    NaN                  NaN                NaN   \n",
       "1                    NaN                  NaN                NaN   \n",
       "7                    NaN                  NaN                NaN   \n",
       "6                    NaN                  NaN                NaN   \n",
       "8                    NaN                  NaN                NaN   \n",
       "\n",
       "   params_algorithm  params_n_neighbors params_weights params_boosting_type  \\\n",
       "10              NaN                 NaN            NaN                 dart   \n",
       "0               NaN                 NaN            NaN                  NaN   \n",
       "2               NaN                 NaN            NaN                  NaN   \n",
       "1               NaN                 NaN            NaN                  NaN   \n",
       "7              auto                 5.0       distance                  NaN   \n",
       "6             brute                 9.0        uniform                  NaN   \n",
       "8             brute                 9.0        uniform                  NaN   \n",
       "\n",
       "   params_class_weight  params_n_jobs  \n",
       "10            balanced           -1.0  \n",
       "0                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "7                  NaN            NaN  \n",
       "6                  NaN            NaN  \n",
       "8                  NaN            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'value', 'datetime_start', 'datetime_complete', 'duration',\n",
       "       'params_criterion', 'params_max_features', 'params_splitter', 'state',\n",
       "       'Model_name', 'params_booster', 'params_learning_rate',\n",
       "       'params_n_estimators', 'params_tree_method', 'params_algorithm',\n",
       "       'params_n_neighbors', 'params_weights', 'params_boosting_type',\n",
       "       'params_class_weight', 'params_n_jobs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['value', 'params_criterion', 'params_max_features', 'params_splitter',\n",
       "       'Model_name', 'params_booster', 'params_learning_rate',\n",
       "       'params_n_estimators', 'params_tree_method', 'params_algorithm',\n",
       "       'params_n_neighbors', 'params_weights', 'params_boosting_type',\n",
       "       'params_class_weight', 'params_n_jobs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_splitter</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params_booster</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>params_algorithm</th>\n",
       "      <th>params_n_neighbors</th>\n",
       "      <th>params_weights</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.985980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light_GBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973820</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972720</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.955599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>5.0</td>\n",
       "      <td>distance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.944959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value params_criterion params_max_features params_splitter  \\\n",
       "10  0.985980              NaN                 NaN             NaN   \n",
       "0   0.973820          entropy                log2            best   \n",
       "2   0.972720             gini                 NaN          random   \n",
       "1   0.969000         log_loss                log2          random   \n",
       "7   0.955599              NaN                 NaN             NaN   \n",
       "6   0.944959              NaN                 NaN             NaN   \n",
       "8   0.944959              NaN                 NaN             NaN   \n",
       "\n",
       "                  Model_name params_booster  params_learning_rate  \\\n",
       "10                 Light_GBM            NaN              0.181309   \n",
       "0   Decision_Tree_Classifier            NaN                   NaN   \n",
       "2   Decision_Tree_Classifier            NaN                   NaN   \n",
       "1   Decision_Tree_Classifier            NaN                   NaN   \n",
       "7             KNN_Classifier            NaN                   NaN   \n",
       "6             KNN_Classifier            NaN                   NaN   \n",
       "8             KNN_Classifier            NaN                   NaN   \n",
       "\n",
       "    params_n_estimators params_tree_method params_algorithm  \\\n",
       "10                121.0                NaN              NaN   \n",
       "0                   NaN                NaN              NaN   \n",
       "2                   NaN                NaN              NaN   \n",
       "1                   NaN                NaN              NaN   \n",
       "7                   NaN                NaN             auto   \n",
       "6                   NaN                NaN            brute   \n",
       "8                   NaN                NaN            brute   \n",
       "\n",
       "    params_n_neighbors params_weights params_boosting_type  \\\n",
       "10                 NaN            NaN                 dart   \n",
       "0                  NaN            NaN                  NaN   \n",
       "2                  NaN            NaN                  NaN   \n",
       "1                  NaN            NaN                  NaN   \n",
       "7                  5.0       distance                  NaN   \n",
       "6                  9.0        uniform                  NaN   \n",
       "8                  9.0        uniform                  NaN   \n",
       "\n",
       "   params_class_weight  params_n_jobs  \n",
       "10            balanced           -1.0  \n",
       "0                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "7                  NaN            NaN  \n",
       "6                  NaN            NaN  \n",
       "8                  NaN            NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[params_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.181309</td>\n",
       "      <td>0.98598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    params_learning_rate    value\n",
       "10              0.181309  0.98598"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[params_name][optuna_study_df_copy[params_name]['Model_name'] == 'Light_GBM'][['params_learning_rate','value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    0.955599\n",
       "6    0.944959\n",
       "8    0.944959\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[params_name][optuna_study_df_copy[params_name]['Model_name'] == 'KNN_Classifier']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[params_name][optuna_study_df_copy[params_name]['Model_name'] == 'Light_GBM'].columns.str.contains('boosting_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([(False, False, False, False, False, False, False, False, False, False, False, True, False, False)], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moptuna_study_df_copy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparams_value\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([(False, False, False, False, False, False, False, False, False, False, False, True, False, False)], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "optuna_study_df_copy[params_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-31 08:49:28,977: INFO: utils: params.yaml yaml_file is loaded]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_splitter</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params_booster</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>params_algorithm</th>\n",
       "      <th>params_n_neighbors</th>\n",
       "      <th>params_weights</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.985980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light_GBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dart</td>\n",
       "      <td>balanced</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973820</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.972720</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969000</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.955599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>5.0</td>\n",
       "      <td>distance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.944959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brute</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value params_criterion params_max_features params_splitter  \\\n",
       "10  0.985980              NaN                 NaN             NaN   \n",
       "0   0.973820          entropy                log2            best   \n",
       "2   0.972720             gini                 NaN          random   \n",
       "1   0.969000         log_loss                log2          random   \n",
       "7   0.955599              NaN                 NaN             NaN   \n",
       "6   0.944959              NaN                 NaN             NaN   \n",
       "8   0.944959              NaN                 NaN             NaN   \n",
       "\n",
       "                  Model_name params_booster  params_learning_rate  \\\n",
       "10                 Light_GBM            NaN              0.181309   \n",
       "0   Decision_Tree_Classifier            NaN                   NaN   \n",
       "2   Decision_Tree_Classifier            NaN                   NaN   \n",
       "1   Decision_Tree_Classifier            NaN                   NaN   \n",
       "7             KNN_Classifier            NaN                   NaN   \n",
       "6             KNN_Classifier            NaN                   NaN   \n",
       "8             KNN_Classifier            NaN                   NaN   \n",
       "\n",
       "    params_n_estimators params_tree_method params_algorithm  \\\n",
       "10                121.0                NaN              NaN   \n",
       "0                   NaN                NaN              NaN   \n",
       "2                   NaN                NaN              NaN   \n",
       "1                   NaN                NaN              NaN   \n",
       "7                   NaN                NaN             auto   \n",
       "6                   NaN                NaN            brute   \n",
       "8                   NaN                NaN            brute   \n",
       "\n",
       "    params_n_neighbors params_weights params_boosting_type  \\\n",
       "10                 NaN            NaN                 dart   \n",
       "0                  NaN            NaN                  NaN   \n",
       "2                  NaN            NaN                  NaN   \n",
       "1                  NaN            NaN                  NaN   \n",
       "7                  5.0       distance                  NaN   \n",
       "6                  9.0        uniform                  NaN   \n",
       "8                  9.0        uniform                  NaN   \n",
       "\n",
       "   params_class_weight  params_n_jobs  \n",
       "10            balanced           -1.0  \n",
       "0                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "7                  NaN            NaN  \n",
       "6                  NaN            NaN  \n",
       "8                  NaN            NaN  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[params_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>accuracy_value</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>0.97382</td>\n",
       "      <td>best</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>0.97272</td>\n",
       "      <td>random</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.96900</td>\n",
       "      <td>random</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  accuracy_value splitter max_features\n",
       "0   entropy         0.97382     best         log2\n",
       "1      gini         0.97272   random          NaN\n",
       "2  log_loss         0.96900   random         log2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_name = optuna_study_df_copy.columns[(optuna_study_df_copy.columns.str.contains('params')) | (optuna_study_df_copy.columns.str.contains('Model_name')) | (optuna_study_df_copy.columns.str.contains('value'))]\n",
    "params = {}\n",
    "for i in optuna_study_df_copy[params_name]['Model_name']:\n",
    "    params[i] = {}\n",
    "    for j in params_yaml['optuna'][i].keys():\n",
    "        params[i][j] = optuna_study_df_copy[params_name][optuna_study_df_copy[params_name]['Model_name'] == i][f'params_{j}'].values.tolist()\n",
    "        params[i]['accuracy_value'] = optuna_study_df_copy[params_name][optuna_study_df_copy[params_name]['Model_name'] == i]['value'].values.tolist()\n",
    "pd.DataFrame(params['Decision_Tree_Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>accuracy_value</th>\n",
       "      <th>weights</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.955599</td>\n",
       "      <td>distance</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>uniform</td>\n",
       "      <td>brute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>uniform</td>\n",
       "      <td>brute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  accuracy_value   weights algorithm\n",
       "7          5.0        0.955599  distance      auto\n",
       "6          9.0        0.944959   uniform     brute\n",
       "8          9.0        0.944959   uniform     brute"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['KNN_Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>accuracy_value</th>\n",
       "      <th>weights</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.955599</td>\n",
       "      <td>distance</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>uniform</td>\n",
       "      <td>brute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.944959</td>\n",
       "      <td>uniform</td>\n",
       "      <td>brute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  accuracy_value   weights algorithm\n",
       "7          5.0        0.955599  distance      auto\n",
       "6          9.0        0.944959   uniform     brute\n",
       "8          9.0        0.944959   uniform     brute"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['KNN_Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>accuracy_value</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dart</td>\n",
       "      <td>0.98598</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>121.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boosting_type  accuracy_value  learning_rate  n_estimators class_weight  \\\n",
       "10          dart         0.98598       0.181309         121.0     balanced   \n",
       "\n",
       "    n_jobs  \n",
       "10    -1.0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['Light_GBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>accuracy_value</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>0.97382</td>\n",
       "      <td>best</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>0.97272</td>\n",
       "      <td>random</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>0.96900</td>\n",
       "      <td>random</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion  accuracy_value splitter max_features\n",
       "0   entropy         0.97382     best         log2\n",
       "1      gini         0.97272   random          NaN\n",
       "2  log_loss         0.96900   random         log2"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['Decision_Tree_Classifier']).sort_values(by = 'accuracy_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2'}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['Decision_Tree_Classifier']).sort_values(by = 'accuracy_value', ascending=False).iloc[:1,:].drop(columns = 'accuracy_value').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart', 'learning_rate': 0.1813086641557807, 'n_estimators': 121.0, 'class_weight': 'balanced', 'n_jobs': -1.0}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['Light_GBM']).sort_values(by = 'accuracy_value', ascending=False).iloc[:1,:].drop(columns = 'accuracy_value').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic_Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mLogisticRegression\u001b[49m, \n\u001b[0;32m      2\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: SGDClassifier,\n\u001b[0;32m      3\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier, \n\u001b[0;32m      4\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAda_Boost\u001b[39m\u001b[38;5;124m'\u001b[39m: AdaBoostClassifier, \n\u001b[0;32m      5\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrad_Boost\u001b[39m\u001b[38;5;124m'\u001b[39m: GradientBoostingClassifier, \n\u001b[0;32m      6\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBagging_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: BaggingClassifier, \n\u001b[0;32m      7\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtraTreesClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: ExtraTreesClassifier, \n\u001b[0;32m      8\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHist_Grad_Boost_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: HistGradientBoostingClassifier, \n\u001b[0;32m      9\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecision_Tree_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: DecisionTreeClassifier,\n\u001b[0;32m     10\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGB_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: XGBClassifier,\n\u001b[0;32m     11\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLight_GBM\u001b[39m\u001b[38;5;124m'\u001b[39m : LGBMClassifier,\n\u001b[0;32m     12\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN_Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: KNeighborsClassifier,\n\u001b[0;32m     13\u001b[0m                   }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "models = {'Logistic_Regression': LogisticRegression, \n",
    "                  'SGD_Classifier': SGDClassifier,\n",
    "                  'Random Forest': RandomForestClassifier, \n",
    "                  'Ada_Boost': AdaBoostClassifier, \n",
    "                  'Grad_Boost': GradientBoostingClassifier, \n",
    "                  'Bagging_Classifier': BaggingClassifier, \n",
    "                  'ExtraTreesClassifier': ExtraTreesClassifier, \n",
    "                  'Hist_Grad_Boost_Classifier': HistGradientBoostingClassifier, \n",
    "                  'Decision_Tree_Classifier': DecisionTreeClassifier,\n",
    "                  'XGB_Classifier': XGBClassifier,\n",
    "                  'Light_GBM' : LGBMClassifier,\n",
    "                  'KNN_Classifier': KNeighborsClassifier,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision_Tree_Classifier': {'accuracy_value': [0.97381998990358,\n",
      "                                                 0.9727196097395168,\n",
      "                                                 0.9690003175835422],\n",
      "                              'criterion': ['entropy', 'gini', 'log_loss'],\n",
      "                              'max_features': ['log2', nan, 'log2'],\n",
      "                              'splitter': ['best', 'random', 'random']},\n",
      " 'KNN_Classifier': {'accuracy_value': [0.9555994803440272,\n",
      "                                       0.9449593754718444,\n",
      "                                       0.9449593754718444],\n",
      "                    'algorithm': ['auto', 'brute', 'brute'],\n",
      "                    'n_neighbors': [5.0, 9.0, 9.0],\n",
      "                    'weights': ['distance', 'uniform', 'uniform']},\n",
      " 'Light_GBM': {'accuracy_value': [0.9859798868557622],\n",
      "               'boosting_type': ['dart'],\n",
      "               'class_weight': ['balanced'],\n",
      "               'learning_rate': [0.1813086641557807],\n",
      "               'n_estimators': [121.0],\n",
      "               'n_jobs': [-1.0]}}\n"
     ]
    }
   ],
   "source": [
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_splitter</th>\n",
       "      <th>state</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params_booster</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>params_algorithm</th>\n",
       "      <th>params_n_neighbors</th>\n",
       "      <th>params_weights</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97382</td>\n",
       "      <td>2024-01-31 07:41:08.839523</td>\n",
       "      <td>2024-01-31 07:45:52.525983</td>\n",
       "      <td>0 days 00:04:43.686460</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.97272</td>\n",
       "      <td>2024-01-31 07:50:26.000225</td>\n",
       "      <td>2024-01-31 07:54:26.238470</td>\n",
       "      <td>0 days 00:04:00.238245</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96900</td>\n",
       "      <td>2024-01-31 07:45:52.528036</td>\n",
       "      <td>2024-01-31 07:50:25.997216</td>\n",
       "      <td>0 days 00:04:33.469180</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number    value              datetime_start           datetime_complete  \\\n",
       "0       0  0.97382  2024-01-31 07:41:08.839523  2024-01-31 07:45:52.525983   \n",
       "2       2  0.97272  2024-01-31 07:50:26.000225  2024-01-31 07:54:26.238470   \n",
       "1       1  0.96900  2024-01-31 07:45:52.528036  2024-01-31 07:50:25.997216   \n",
       "\n",
       "                 duration params_criterion params_max_features  \\\n",
       "0  0 days 00:04:43.686460          entropy                log2   \n",
       "2  0 days 00:04:00.238245             gini                 NaN   \n",
       "1  0 days 00:04:33.469180         log_loss                log2   \n",
       "\n",
       "  params_splitter     state                Model_name params_booster  \\\n",
       "0            best  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "2          random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "1          random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "\n",
       "   params_learning_rate  params_n_estimators params_tree_method  \\\n",
       "0                   NaN                  NaN                NaN   \n",
       "2                   NaN                  NaN                NaN   \n",
       "1                   NaN                  NaN                NaN   \n",
       "\n",
       "  params_algorithm  params_n_neighbors params_weights params_boosting_type  \\\n",
       "0              NaN                 NaN            NaN                  NaN   \n",
       "2              NaN                 NaN            NaN                  NaN   \n",
       "1              NaN                 NaN            NaN                  NaN   \n",
       "\n",
       "  params_class_weight  params_n_jobs  \n",
       "0                 NaN            NaN  \n",
       "2                 NaN            NaN  \n",
       "1                 NaN            NaN  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_study_df_copy[optuna_study_df_copy['Model_name']=='Decision_Tree_Classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auto', 'brute', 'brute']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(params['KNN_Classifier']['algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>random</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  criterion splitter max_features\n",
       "0   entropy     best         log2\n",
       "1      gini   random          NaN\n",
       "2  log_loss   random         log2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(params['Decision_Tree_Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_splitter</th>\n",
       "      <th>state</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params_booster</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_tree_method</th>\n",
       "      <th>params_algorithm</th>\n",
       "      <th>params_n_neighbors</th>\n",
       "      <th>params_weights</th>\n",
       "      <th>params_boosting_type</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_n_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.97382</td>\n",
       "      <td>2024-01-31 07:41:08.839523</td>\n",
       "      <td>2024-01-31 07:45:52.525983</td>\n",
       "      <td>0 days 00:04:43.686460</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.97272</td>\n",
       "      <td>2024-01-31 07:50:26.000225</td>\n",
       "      <td>2024-01-31 07:54:26.238470</td>\n",
       "      <td>0 days 00:04:00.238245</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.96900</td>\n",
       "      <td>2024-01-31 07:45:52.528036</td>\n",
       "      <td>2024-01-31 07:50:25.997216</td>\n",
       "      <td>0 days 00:04:33.469180</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>Decision_Tree_Classifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number    value              datetime_start           datetime_complete  \\\n",
       "0       0  0.97382  2024-01-31 07:41:08.839523  2024-01-31 07:45:52.525983   \n",
       "2       2  0.97272  2024-01-31 07:50:26.000225  2024-01-31 07:54:26.238470   \n",
       "1       1  0.96900  2024-01-31 07:45:52.528036  2024-01-31 07:50:25.997216   \n",
       "\n",
       "                 duration params_criterion params_max_features  \\\n",
       "0  0 days 00:04:43.686460          entropy                log2   \n",
       "2  0 days 00:04:00.238245             gini                 NaN   \n",
       "1  0 days 00:04:33.469180         log_loss                log2   \n",
       "\n",
       "  params_splitter     state                Model_name params_booster  \\\n",
       "0            best  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "2          random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "1          random  COMPLETE  Decision_Tree_Classifier            NaN   \n",
       "\n",
       "   params_learning_rate  params_n_estimators params_tree_method  \\\n",
       "0                   NaN                  NaN                NaN   \n",
       "2                   NaN                  NaN                NaN   \n",
       "1                   NaN                  NaN                NaN   \n",
       "\n",
       "  params_algorithm  params_n_neighbors params_weights params_boosting_type  \\\n",
       "0              NaN                 NaN            NaN                  NaN   \n",
       "2              NaN                 NaN            NaN                  NaN   \n",
       "1              NaN                 NaN            NaN                  NaN   \n",
       "\n",
       "  params_class_weight  params_n_jobs  \n",
       "0                 NaN            NaN  \n",
       "2                 NaN            NaN  \n",
       "1                 NaN            NaN  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['distance', 'uniform', 'uniform'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['KNN_Classifier']['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criterion', 'splitter', 'max_features']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(params_yaml['optuna']['Decision_Tree_Classifier'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Invalid config statement: \"['optuna']['Logistic_Regression']['penalty']\", should be `Class.trait = value`.\n"
     ]
    }
   ],
   "source": [
    "config['optuna']['Logistic_Regression']['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[43mconfig\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic_Regression\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "list(config['optuna']['Logistic_Regression'].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Invalid config statement: \"['optuna']['Logistic_Regression']['penalty']\", should be `Class.trait = value`.\n"
     ]
    }
   ],
   "source": [
    "config['optuna']['Logistic_Regression']['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 171)\n"
     ]
    }
   ],
   "source": [
    "train_path = Path('F:\\iNeuron\\Projects\\scania_failures_2\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')\n",
    "# test_path = Path('F:\\iNeuron\\Projects\\scania_failures_2\\\\artifacts\\data\\processed\\stage_2_processing\\processed_test_data.csv')\n",
    "#size = input(\"Enter the size\")\n",
    "train_df = pd.read_csv(train_path)#.iloc[:eval(size),:]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Input!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    size = input(\"Enter the size\")\n",
    "    train_df = pd.read_csv(train_path).iloc[:eval(size),:]\n",
    "    print(train_df.shape)\n",
    "except:\n",
    "    print(\"Invalid Input!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 171)\n"
     ]
    }
   ],
   "source": [
    "#size = input(\"Enter the size\")\n",
    "train_df = pd.read_csv(train_path)#.iloc[:eval(size),:]\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if size:\n",
    "    print (\"True\")\n",
    "else: \n",
    "    print (\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76698.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33058.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60874.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>153002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.640000e+02</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998500.0</td>\n",
       "      <td>566884.0</td>\n",
       "      <td>1290398.0</td>\n",
       "      <td>1218244.0</td>\n",
       "      <td>1019768.0</td>\n",
       "      <td>717762.0</td>\n",
       "      <td>898642.0</td>\n",
       "      <td>28588.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>2286.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130707e+09</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>21126.0</td>\n",
       "      <td>68424.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>792.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>80292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352.0</td>\n",
       "      <td>222654.0</td>\n",
       "      <td>347378.0</td>\n",
       "      <td>225724.0</td>\n",
       "      <td>194440.0</td>\n",
       "      <td>165070.0</td>\n",
       "      <td>802280.0</td>\n",
       "      <td>388422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>40222.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066.0</td>\n",
       "      <td>183200.0</td>\n",
       "      <td>344546.0</td>\n",
       "      <td>254068.0</td>\n",
       "      <td>225148.0</td>\n",
       "      <td>158304.0</td>\n",
       "      <td>170384.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0       76698.0     NaN  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1       33058.0     NaN  0.000000e+00     NaN     0.0     0.0     0.0     0.0   \n",
       "2       41040.0     NaN  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3          12.0     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4       60874.0     NaN  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...           ...     ...     ...     ...     ...     ...   \n",
       "59995  153002.0     NaN  6.640000e+02   186.0     0.0     0.0     0.0     0.0   \n",
       "59996    2286.0     NaN  2.130707e+09   224.0     0.0     0.0     0.0     0.0   \n",
       "59997     112.0     0.0  2.130706e+09    18.0     0.0     0.0     0.0     0.0   \n",
       "59998   80292.0     NaN  2.130706e+09   494.0     0.0     0.0     0.0     0.0   \n",
       "59999   40222.0     NaN  6.980000e+02   628.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       ag_002  ag_003  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
       "0         0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
       "1         0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
       "2         0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
       "3         0.0   318.0  ...      240.0      46.0       58.0       44.0   \n",
       "4         0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
       "...       ...     ...  ...        ...       ...        ...        ...   \n",
       "59995     0.0  2564.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
       "59996     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
       "59997     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
       "59998     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
       "59999     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
       "\n",
       "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
       "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
       "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
       "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
       "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
       "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
       "...          ...       ...       ...       ...     ...     ...  \n",
       "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
       "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
       "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
       "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
       "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
       "\n",
       "[60000 rows x 171 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 171)\n",
      "(10000, 170) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "train_path = Path('F:\\iNeuron\\Projects\\scania_failures_2\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path).iloc[:10000,:]\n",
    "# test_df = pd.read_csv(test_path).iloc[:35000,:]\n",
    "\n",
    "x_train = train_df.drop(columns='class')\n",
    "y_train = train_df['class']\n",
    "# x_test = test_df.drop(columns='class')\n",
    "# y_test = test_df['class']\n",
    "print(train_df.shape)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-27 13:43:14,562] A new study created in RDB with name: no-name-45a9eb95-ada3-46ae-a641-2000a1f72f0f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0\n",
      "(48000, 170) (48000,) (12000, 170) (12000,)\n",
      "Starting pipeline transformation of Xtrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-27 13:44:02,429] Trial 0 failed with parameters: {'n_estimators': 852, 'criterion': 'entropy', 'max_features': None, 'class_weight': 'balanced'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9476\\3211324518.py\", line 46, in objective\n",
      "    X_train_transformed = pipeline.fit_transform(X = x_train_, y = y_train_)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\impute\\_knn.py\", line 365, in transform\n",
      "    for chunk in gen:\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 2018, in pairwise_distances_chunked\n",
      "    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 2196, in pairwise_distances\n",
      "    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1766, in _parallel_pairwise\n",
      "    return func(X, Y, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 511, in nan_euclidean_distances\n",
      "    present_count = np.dot(present_X, present_Y.T)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-27 13:44:02,475] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 74\u001b[0m\n\u001b[0;32m     70\u001b[0m pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner()\n\u001b[0;32m     71\u001b[0m find_param\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mcreate_study(storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmysql://root:qwerty12345@localhost/example\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     72\u001b[0m                                load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m                                pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mfind_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[21], line 46\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial, data)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train_\u001b[38;5;241m.\u001b[39mshape, y_train_\u001b[38;5;241m.\u001b[39mshape, x_test_\u001b[38;5;241m.\u001b[39mshape, y_test_\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting pipeline transformation of Xtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting SMOTE transformation of Xtrain,Ytrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m X_train_smote,y_train_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X \u001b[38;5;241m=\u001b[39m X_train_transformed,y \u001b[38;5;241m=\u001b[39m y_train_)\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    375\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 957\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    959\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\impute\\_knn.py:365\u001b[0m, in \u001b[0;36mKNNImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;66;03m# process in fixed-memory chunks\u001b[39;00m\n\u001b[0;32m    357\u001b[0m gen \u001b[38;5;241m=\u001b[39m pairwise_distances_chunked(\n\u001b[0;32m    358\u001b[0m     X[row_missing_idx, :],\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m     reduce_func\u001b[38;5;241m=\u001b[39mprocess_chunk,\n\u001b[0;32m    364\u001b[0m )\n\u001b[1;32m--> 365\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# process_chunk modifies X in place. No return value.\u001b[39;49;00m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_empty_features:\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2018\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2016\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2017\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2018\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2020\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2194\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1763\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mf:\\iNeuron\\Projects\\scania_failures_2\\scania_truck\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:511\u001b[0m, in \u001b[0;36mnan_euclidean_distances\u001b[1;34m(X, Y, squared, missing_values, copy)\u001b[0m\n\u001b[0;32m    509\u001b[0m present_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m missing_X\n\u001b[0;32m    510\u001b[0m present_Y \u001b[38;5;241m=\u001b[39m present_X \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m X \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m~\u001b[39mmissing_Y\n\u001b[1;32m--> 511\u001b[0m present_count \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpresent_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresent_Y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m distances[present_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# avoid divide by zero\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from src.utils import eval_metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.combine import SMOTETomek\n",
    "from src.config.configuration_manager import ConfigurationManager\n",
    "\n",
    "\n",
    "# from imblearn.pipeline import Pipeline\n",
    "# from src.config.configuration_manager import ConfigurationManager\n",
    "# obj = ConfigurationManager()\n",
    "skf = StratifiedKFold(n_splits=5,shuffle= False, random_state=None)\n",
    "def objective(trial, data = train_df):\n",
    "  # train_x,test_x,y_train,y_test=train_test_split(data,target,test_size=0.20,random_state=25)\n",
    "  # param= {list(config['optuna']['ExtraTreesClassifier'].keys())[0] : eval(config['optuna']['ExtraTreesClassifier']['penalty'])}\n",
    "\n",
    "  # preprocessor_config = obj.get_preprocessor_config()\n",
    "  # schema = load_yaml(obj.schema)\n",
    "  # target = list(schema.Target.keys())[0]\n",
    "  pipeline = Pipeline(steps=[('Knn_imputer',KNNImputer()),\n",
    "                             ('Robust_Scaler',RobustScaler())],\n",
    "                            verbose=True)\n",
    "  smote = SMOTETomek(n_jobs=-1,sampling_strategy='minority',random_state=8)\n",
    "  X = data.drop(columns='class')\n",
    "  y = data['class']\n",
    "  # space = {}\n",
    "  score = []\n",
    "  space = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "    'criterion': trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini']),\n",
    "    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "    'class_weight': trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])}\n",
    "  # obj = ConfigurationManager()\n",
    "  # for key,value in obj.config_path['optuna']['ExtraTreesClassifier'].items():\n",
    "  #   space[key] = eval(value)\n",
    "  for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    print (\"Fold: \",fold)\n",
    "    x_train_ = data.drop(columns = 'class').iloc[train_indices]\n",
    "    y_train_ = data['class'].iloc[train_indices]\n",
    "    x_test_  = data.drop(columns = 'class').iloc[test_indices]\n",
    "    y_test_  = data['class'].iloc[test_indices]\n",
    "\n",
    "    print(x_train_.shape, y_train_.shape, x_test_.shape, y_test_.shape)\n",
    "    print(\"Starting pipeline transformation of Xtrain\")\n",
    "    X_train_transformed = pipeline.fit_transform(X = x_train_, y = y_train_)\n",
    "    print(\"Starting SMOTE transformation of Xtrain,Ytrain\")\n",
    "    X_train_smote,y_train_smote = smote.fit_resample(X = X_train_transformed,y = y_train_)\n",
    "\n",
    "    print(\"Starting pipeline transformation of Xtest\")\n",
    "    X_test_transformed = pipeline.transform(X = x_test_)\n",
    "    print(\"Starting SMOTE transformation of Xtest,Ytest\")\n",
    "    X_test_smote,y_test_smote = smote.fit_resample(X = X_test_transformed,y = y_test_)\n",
    "\n",
    "\n",
    "    print(X_train_smote.shape, y_train_smote.shape, X_test_smote.shape, y_test_smote.shape)\n",
    "    log_reg=ExtraTreesClassifier(**space)\n",
    "    print(\"Fitting model\")\n",
    "    log_reg.fit(X_train_smote,y_train_smote)\n",
    "    y_predict=log_reg.predict(X_test_smote)\n",
    "    cost = eval_metrics(y_true = y_test_smote , y_pred = y_predict)\n",
    "    print (f\"Cost in fold{fold}: {cost}\")\n",
    "    trial.report(cost, fold)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "    else:\n",
    "       score.append(cost)\n",
    "  return np.mean(score)\n",
    "\n",
    "pruner=optuna.pruners.MedianPruner()\n",
    "find_param=optuna.create_study(storage='mysql://root:qwerty12345@localhost/example',\n",
    "                               load_if_exists=True,direction = \"minimize\",\n",
    "                               pruner=pruner)\n",
    "find_param.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.storages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33097.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_param.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_class_weight</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_features</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>system_attrs_completed_rung_0</th>\n",
       "      <th>system_attrs_completed_rung_1</th>\n",
       "      <th>system_attrs_completed_rung_2</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33097.0</td>\n",
       "      <td>2024-01-14 15:00:07.599244</td>\n",
       "      <td>2024-01-14 15:07:40.859962</td>\n",
       "      <td>0 days 00:07:33.260718</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34479.0</td>\n",
       "      <td>2024-01-14 15:07:40.867896</td>\n",
       "      <td>2024-01-14 15:16:08.830188</td>\n",
       "      <td>0 days 00:08:27.962292</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>343</td>\n",
       "      <td>26550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33244.0</td>\n",
       "      <td>2024-01-14 15:16:08.835107</td>\n",
       "      <td>2024-01-14 15:25:31.428111</td>\n",
       "      <td>0 days 00:09:22.593004</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>429</td>\n",
       "      <td>13620.0</td>\n",
       "      <td>54620.0</td>\n",
       "      <td>28570.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>2024-01-14 15:25:31.431102</td>\n",
       "      <td>2024-01-14 15:27:25.583525</td>\n",
       "      <td>0 days 00:01:54.152423</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>375</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>2024-01-14 15:27:25.585447</td>\n",
       "      <td>2024-01-14 15:29:52.244854</td>\n",
       "      <td>0 days 00:02:26.659407</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>961</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>2024-01-14 15:29:52.247768</td>\n",
       "      <td>2024-01-14 15:34:14.847344</td>\n",
       "      <td>0 days 00:04:22.599576</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>647</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17100.0</td>\n",
       "      <td>2024-01-14 15:34:14.848285</td>\n",
       "      <td>2024-01-14 15:38:53.651309</td>\n",
       "      <td>0 days 00:04:38.803024</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>705</td>\n",
       "      <td>17100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>18130.0</td>\n",
       "      <td>2024-01-14 15:38:53.653227</td>\n",
       "      <td>2024-01-14 15:40:40.120447</td>\n",
       "      <td>0 days 00:01:46.467220</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>865</td>\n",
       "      <td>18130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>43095.0</td>\n",
       "      <td>2024-01-14 15:40:40.121450</td>\n",
       "      <td>2024-01-14 16:08:36.728736</td>\n",
       "      <td>0 days 00:27:56.607286</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>907</td>\n",
       "      <td>57080.0</td>\n",
       "      <td>54550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>34560.0</td>\n",
       "      <td>2024-01-14 16:08:36.731746</td>\n",
       "      <td>2024-01-14 16:18:27.913535</td>\n",
       "      <td>0 days 00:09:51.181789</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>889</td>\n",
       "      <td>34560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRUNED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number    value             datetime_start          datetime_complete  \\\n",
       "0       0  33097.0 2024-01-14 15:00:07.599244 2024-01-14 15:07:40.859962   \n",
       "1       1  34479.0 2024-01-14 15:07:40.867896 2024-01-14 15:16:08.830188   \n",
       "2       2  33244.0 2024-01-14 15:16:08.835107 2024-01-14 15:25:31.428111   \n",
       "3       3  15600.0 2024-01-14 15:25:31.431102 2024-01-14 15:27:25.583525   \n",
       "4       4  14130.0 2024-01-14 15:27:25.585447 2024-01-14 15:29:52.244854   \n",
       "5       5  17090.0 2024-01-14 15:29:52.247768 2024-01-14 15:34:14.847344   \n",
       "6       6  17100.0 2024-01-14 15:34:14.848285 2024-01-14 15:38:53.651309   \n",
       "7       7  18130.0 2024-01-14 15:38:53.653227 2024-01-14 15:40:40.120447   \n",
       "8       8  43095.0 2024-01-14 15:40:40.121450 2024-01-14 16:08:36.728736   \n",
       "9       9  34560.0 2024-01-14 16:08:36.731746 2024-01-14 16:18:27.913535   \n",
       "\n",
       "                duration params_class_weight params_criterion  \\\n",
       "0 0 days 00:07:33.260718            balanced          entropy   \n",
       "1 0 days 00:08:27.962292  balanced_subsample          entropy   \n",
       "2 0 days 00:09:22.593004  balanced_subsample         log_loss   \n",
       "3 0 days 00:01:54.152423  balanced_subsample         log_loss   \n",
       "4 0 days 00:02:26.659407  balanced_subsample             gini   \n",
       "5 0 days 00:04:22.599576            balanced          entropy   \n",
       "6 0 days 00:04:38.803024            balanced         log_loss   \n",
       "7 0 days 00:01:46.467220            balanced             gini   \n",
       "8 0 days 00:27:56.607286            balanced         log_loss   \n",
       "9 0 days 00:09:51.181789  balanced_subsample             gini   \n",
       "\n",
       "  params_max_features  params_n_estimators  system_attrs_completed_rung_0  \\\n",
       "0                log2                  260                            NaN   \n",
       "1                sqrt                  343                        26550.0   \n",
       "2                log2                  429                        13620.0   \n",
       "3                sqrt                  375                        15600.0   \n",
       "4                log2                  961                        14130.0   \n",
       "5                None                  647                        17090.0   \n",
       "6                None                  705                        17100.0   \n",
       "7                log2                  865                        18130.0   \n",
       "8                None                  907                        57080.0   \n",
       "9                sqrt                  889                        34560.0   \n",
       "\n",
       "   system_attrs_completed_rung_1  system_attrs_completed_rung_2     state  \n",
       "0                            NaN                            NaN  COMPLETE  \n",
       "1                            NaN                            NaN  COMPLETE  \n",
       "2                        54620.0                        28570.0  COMPLETE  \n",
       "3                            NaN                            NaN    PRUNED  \n",
       "4                            NaN                            NaN    PRUNED  \n",
       "5                            NaN                            NaN    PRUNED  \n",
       "6                            NaN                            NaN    PRUNED  \n",
       "7                            NaN                            NaN    PRUNED  \n",
       "8                        54550.0                            NaN  COMPLETE  \n",
       "9                            NaN                            NaN    PRUNED  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_param.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 260,\n",
       " 'criterion': 'entropy',\n",
       " 'max_features': 'log2',\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_param.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_param.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll.base import scope\n",
    "import hyperopt\n",
    "a = scope.int(hp.quniform('n_estimators', 100, 2000, 1))\n",
    "\n",
    "print(hyperopt.pyll.stochastic.sample(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['hyperopt']['Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['hyperopt']['Random Forest'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "space = {}\n",
    "for key,value in config['hyperopt']['Random Forest'].items():\n",
    "    space[key] = eval(value)\n",
    "def objective(space):\n",
    "    hp_rand_forest = RandomForestClassifier(**space)\n",
    "    hp_rand_forest.fit(train_x,y_train)\n",
    "    y_pred = hp_rand_forest.predict(test_x)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "    cost = float((10*fp)+(500*fn))\n",
    "    return cost\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 10,\n",
    "            trials= trials)\n",
    "best_randf=space_eval(space,best)\n",
    "best_randf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.average_best_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_randf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {'n_estimators': 352,\n",
    " 'criterion': 'entropy',\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': 'balanced_subsample'}\n",
    "randf=RandomForestClassifier(**b)\n",
    "randf.fit(train_x,y_train)\n",
    "y_pred=randf.predict(test_x)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost = float((10*fp)+(500*fn))\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = XGBClassifier(njobs = -1)\n",
    "model_name = 'XGB_Classifier'\n",
    "params_config = load_yaml(PARAMS_PATH)\n",
    "\n",
    "# def cost_scorer(estimator, X, y):\n",
    "#     x_train_, x_test_, y_train_, y_test_ = train_test_split(X,y, random_state=8, test_size = 0.25)\n",
    "#     estimator.fit(x_train_,y_train_)\n",
    "#     y_pred = estimator.predict(x_test_)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true=y_test_, y_pred=y_pred).ravel()\n",
    "#     cost = float((10*fp)+(500*fn))\n",
    "#     return cost\n",
    "\n",
    "params_grid = dict(params_config.randomized_search_cv[model_name])\n",
    "random_search_cv = RandomizedSearchCV(estimator = model,\n",
    "                                        param_distributions = params_grid,\n",
    "                                        n_iter = 5,\n",
    "                                        scoring = 'accuracy',\n",
    "                                        n_jobs = -1,\n",
    "                                        verbose = 3,\n",
    "                                        random_state = 8\n",
    "                                        )\n",
    "random_search_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**random_search_cv.best_params_)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost = float((10*fp)+(500*fn))\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the User Defined Function: hyper_parameter_tuning()\n",
    "This is done to call optuna and hyperopt at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import parameter_tuning\n",
    "report = parameter_tuning(model_class = SGDClassifier,\n",
    "                          model_name = 'SGD_Classifier',\n",
    "                          x_train = x_train,\n",
    "                          x_test = x_test,\n",
    "                          y_train = y_train,\n",
    "                          y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Cost': 437200.0}, 'SGD_Classifier': {'Optuna': {'cost': 31760.0, 'params': {'loss': 'squared_error'}}, 'HyperOpt': {'cost': 4840.0, 'params': {'loss': 'squared_error'}}, 'Best_Params': {'loss': 'squared_error'}, 'Cost': 4840.0}}\n",
    "costs = [value['Cost'] for value in report.values()]\n",
    "min_cost = min(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = min(report['Optuna']['cost'],report['HyperOpt']['cost'])\n",
    "if min_value == report['Optuna']['cost']:\n",
    "    params = report['Optuna']['params']\n",
    "else:\n",
    "    params = report['HyperOpt']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Best_Cost': 437200.0}, 'SGD_Classifier': {'Optuna': {'cost': 125050.0, 'params': {'loss': 'log_loss'}}, 'HyperOpt': \n",
    "{'cost': 15060.0, 'params': {'loss': 'hinge'}}, 'Best_Params': {'loss': 'hinge'}, 'Best_Cost': 15060.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['SGD_Classifier'].keys()\n",
    "costs = [value['Best_Cost'] for value in dictionary.values()]\n",
    "min_cost = min(costs)\n",
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic_Regression': LogisticRegression(), \n",
    "            'SGD_Classifier': SGDClassifier(),\n",
    "            'Random Forest': RandomForestClassifier, \n",
    "            'Ada_Boost': AdaBoostClassifier, \n",
    "            'Grad_Boost': GradientBoostingClassifier, \n",
    "            'Bagging_Classifier': BaggingClassifier, \n",
    "            'ExtraTreesClassifier': ExtraTreesClassifier, \n",
    "            'Hist_Grad_Boost_Classifier': HistGradientBoostingClassifier, \n",
    "            'Decision_Tree_Classifier': DecisionTreeClassifier,\n",
    "            'XGB_Classifier': XGBClassifier,\n",
    "            'KNN_Classifier': KNeighborsClassifier,\n",
    "            'MLP_Classifier': MLPClassifier\n",
    "            }\n",
    "for i in dictionary.keys():\n",
    "    if min_cost == dictionary[i]['Best_Cost']:\n",
    "        best_params_so_far = dictionary[i]['Best_Params']\n",
    "print(best_params_so_far)\n",
    "\n",
    "\n",
    "##Same code as a list comprehension\n",
    "best_params_so_far_ = [(i, min_cost, dictionary[i]['Best_Params']) for i in dictionary.keys() if min_cost == dictionary[i]['Best_Cost']]\n",
    "print(best_params_so_far_[0])\n",
    "\n",
    "model = models[best_params_so_far_[0][0]]\n",
    "model(**best_params_so_far_[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetching the dataframe of 1st five best models for Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_ = sorted(dictionary.items(), key = lambda x: x[1]['Best_Cost'])[:5]\n",
    "best_models = [best_models_[i][0] for i in range(len(best_models_))]\n",
    "best_models_with_params = []\n",
    "for i in best_models:\n",
    "    best_models_with_params.append((i,dictionary[i]['Best_Params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_with_params[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_with_params[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = {}\n",
    "for i in range(len(best_models_with_params)):\n",
    "    best_estimators[best_models_with_params[i][0]] = models[best_models_with_params[i][0]](**best_models_with_params[i][1])\n",
    "best_estimators = list(zip(best_estimators.keys(),best_estimators.values()))\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': None,\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(penalty=None).get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators[1][1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Best_Cost': 437200.0}}\n",
    "my_dict.values()\n",
    "# [value['Best_Cost'] for value in my_dict.values()]\n",
    "for i in my_dict.values():\n",
    "    value = i['Best_Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i['Best_Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('KNN_Classifier', 90240.0, {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute'})][0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config_Manager - Sorting Report Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.configuration_manager import ConfigurationManager\n",
    "obj = ConfigurationManager()\n",
    "preprocessor_config = obj.get_preprocessor_config()\n",
    "os.listdir(preprocessor_config.root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(preprocessor_config.preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['name'] = 'LogisticRegression()'\n",
    "metrics['b_score'] = 9999999999.32\n",
    "metrics['a_score'] = 3.23\n",
    "\n",
    "report = {}\n",
    "report['log_reg'] = metrics\n",
    "\n",
    "metrics_a={}\n",
    "metrics_a['name'] = 'SVC()'\n",
    "metrics_a['b_score'] = 9934\n",
    "metrics_a['a_score'] = 23534.23\n",
    "\n",
    "report['svm'] = metrics_a\n",
    "\n",
    "name = max(report.keys(), key = lambda k: report[k].get('a_score', 0))\n",
    "report[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_yaml,load_binary\n",
    "\n",
    "model_dict = load_yaml(filepath = Path('artifacts\\metrics\\metrics.yaml'))\n",
    "\n",
    "model = load_binary(filepath = Path('artifacts\\model\\model.joblib'))\n",
    "\n",
    "preprocessor = load_binary(filepath = Path('artifacts\\preprocessor\\preprocessor.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')\n",
    "X = df.drop(columns = 'class').iloc[:1000,:]\n",
    "y = df['class'].iloc[:1000]\n",
    "X_transformed = preprocessor.transform(X = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_transformed).isna().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "smote = SMOTETomek(sampling_strategy = 'minority',\n",
    "                   random_state = 8,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "x_smote, y_smote = smote.fit_resample(X = X_transformed,\n",
    "                                      y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (balanced_accuracy_score, f1_score,\n",
    "                             accuracy_score, confusion_matrix)\n",
    "\n",
    "y_pred = model.predict(x_smote)\n",
    "balanced_accuracy_score_ = float(balanced_accuracy_score(y_true=y_smote, y_pred=y_pred))\n",
    "f1_score_ = float(f1_score(y_true=y_smote, y_pred=y_pred))\n",
    "accuracy_score_ = float(accuracy_score(y_true=y_smote, y_pred=y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_smote, y_pred=y_pred).ravel()\n",
    "cost_ = float((10*fp)+(500*fn))\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_}')\n",
    "print(f'accuracy_score_: {accuracy_score_}')\n",
    "print(f'f1_score_: {f1_score_}')\n",
    "print(f'cost_: {cost_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import save_yaml\n",
    "save_yaml(file=report,filepath='f:\\iNeuron\\Projects\\Scania_Truck_Failures\\sample.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\Scania_Truck_Failures')\n",
    "with open (Path('.\\\\config\\\\config.yaml')) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print({list(config['data_ingestion_config']['test_data3'].keys())[0]:list(config['data_ingestion_config']['test_data3'].values())[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['data_ingestion_config']['test_data3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(os.listdir('../notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('F:\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['class'] = df1['class'].map({'neg':0,'pos':1})\n",
    "df1.replace('na',np.nan,inplace=True)\n",
    "col_list = [i for i in df1.columns if i != 'class']\n",
    "for i in col_list:\n",
    "    df1[i]=df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = df1.drop(columns = 'class').describe()==df.drop(columns='class').describe()\n",
    "for i in check_df.columns:\n",
    "    print(i,check_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = pd.read_csv('F:\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_test_set.csv')\n",
    "test_df1['class'] = test_df1['class'].map({'neg':0,'pos':1})\n",
    "test_df1.replace('na',np.nan,inplace=True)\n",
    "col_list = [i for i in test_df1.columns if i != 'class']\n",
    "for i in col_list:\n",
    "    test_df1[i]=test_df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check_df = test_df.drop(columns = 'class').describe()==test_df1.drop(columns='class').describe()\n",
    "for i in test_check_df.columns:\n",
    "    print(i,test_check_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"artifacts\\data\\processed\\stage_2_processing\\processed_train_data.csv\").iloc[:1000,:]\n",
    "test_df = pd.read_csv(\"artifacts\\data\\processed\\stage_2_processing\\processed_test_data.csv\").iloc[:1000,:]\n",
    "\n",
    "x_train = train_df.drop(columns = 'class')\n",
    "y_train = train_df['class']\n",
    "x_test = test_df.drop(columns = 'class')\n",
    "y_test = test_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic_Regression': LogisticRegression(), \n",
    "        'SGD_Classifier': SGDClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(), \n",
    "        'Ada_Boost': AdaBoostClassifier(), \n",
    "        'Grad_Boost': GradientBoostingClassifier(), \n",
    "        'Bagging_Classifier': BaggingClassifier(), \n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(), \n",
    "        'Hist_Grad_Boost_Classifier': HistGradientBoostingClassifier(), \n",
    "        'Decision_Tree_Classifier': DecisionTreeClassifier(),\n",
    "        'XGB_Classifier': XGBClassifier(),\n",
    "        'KNN_Classifier': KNeighborsClassifier(),\n",
    "        'MLP_Classifier': MLPClassifier()\n",
    "        }\n",
    "report = {}\n",
    "# metrics_list = ['balanced_accuracy_score','f1_score','accuracy_score']\n",
    "for model_name,model in models.items():\n",
    "        print(model_name)\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        metrics = {}\n",
    "        metrics['balanced_accuracy_score'] = float(balanced_accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        metrics['f1_score'] = float(f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        metrics['accuracy_score'] = float(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "        metrics['cost'] = float((10*fp)+(500*fn))\n",
    "\n",
    "        print(metrics,'\\n')\n",
    "\n",
    "        report[model_name] = metrics\n",
    "\n",
    "best_model_name_by_cost = min(report.keys(), key = lambda k: report[k].get('cost', 0))\n",
    "print(\"\\nBest Model:\")\n",
    "print(models[best_model_name_by_cost])\n",
    "print(report[best_model_name_by_cost],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.sort_values(by ='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = sorted(report.items(), key=lambda x: x[1]['cost'])[:5]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_names_ = [best_models[i][0] for i in range(len(best_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = {}\n",
    "for i in best_models_names_:\n",
    "    best_estimators[i] = models[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators_copy = best_estimators.copy()\n",
    "best_estimators_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators_copy = list(zip(best_estimators_copy.keys(),best_estimators_copy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_classifier = StackingClassifier(estimators = best_estimators_copy,\n",
    "                                        final_estimator =  AdaBoostClassifier(),\n",
    "                                        cv = 5,\n",
    "                                        n_jobs = -1,\n",
    "                                        passthrough = False,\n",
    "                                        verbose = 3)\n",
    "\n",
    "stacked_classifier.fit(x_train,y_train)\n",
    "y_pred = stacked_classifier.predict(x_test)\n",
    "\n",
    "balanced_accuracy_score_ = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1_score_= f1_score(y_true=y_test, y_pred=y_pred)\n",
    "accuracy_score_ = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost_ = (10*fp)+(500*fn)\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_}')\n",
    "print(f'f1_score_: {f1_score_}')\n",
    "print(f'accuracy_score_: {accuracy_score_}')\n",
    "print(f'cost_: {cost_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier_ = VotingClassifier(estimators = best_estimators_copy,\n",
    "                                      voting = \"soft\",\n",
    "                                    weights = None,\n",
    "                                    n_jobs = -1,\n",
    "                                    verbose = True)\n",
    "voting_classifier_.fit(x_train,y_train)\n",
    "y_pred = voting_classifier_.predict(x_test)\n",
    "\n",
    "balanced_accuracy_score_voting = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1_score_voting= f1_score(y_true=y_test, y_pred=y_pred)\n",
    "accuracy_score_voting = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost_voting = (10*fp)+(500*fn)\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_voting}')\n",
    "print(f'f1_score_: {f1_score_voting}')\n",
    "print(f'accuracy_score_: {accuracy_score_voting}')\n",
    "print(f'cost_: {cost_voting}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('F:\\\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace('na',np.nan,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns = 'class').isna().sum() == df.drop(columns = 'class').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = df1.drop(columns = 'class').columns.tolist()\n",
    "for i in cols_list:\n",
    "    df1[i] = df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df1 = df1.drop(columns = 'class').describe() == df.drop(columns = 'class').describe()\n",
    "for i in check_df1.columns:\n",
    "    print(i, check_df1[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('.\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('F:\\\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.replace('na',np.nan,inplace = True)\n",
    "test_col_list = [i for i in df3.columns if i != 'class']\n",
    "for i in test_col_list:\n",
    "    df3[i]=df3[i].astype('float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df3.drop(columns = 'class').isna().sum() == df2.drop(columns = 'class').isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df2 = df3.drop(columns = 'class').describe() == df2.drop(columns = 'class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in check_df2.columns:\n",
    "    print(i, check_df2[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\iNeuron\\\\Projects\\\\scania_failures_2\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\scania_failures_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-06 15:29:28,981: INFO: utils: schema.yaml yaml_file is loaded]\n"
     ]
    }
   ],
   "source": [
    "from src.utils import load_yaml\n",
    "from src.constants import SCHEMA_PATH\n",
    "import pandas as pd\n",
    "\n",
    "schema = load_yaml(SCHEMA_PATH)\n",
    "\n",
    "test_data = pd.read_csv(r'F:\\iNeuron\\Projects\\scania_failures_2\\artifacts\\data\\processed\\stage_2_processing\\processed_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(schema['Features'].keys()) == list(test_data.drop(columns = ['class']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001',\n",
      " 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009',\n",
      " 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000',\n",
      " 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000',\n",
      " 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007',\n",
      " 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005',\n",
      " 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003',\n",
      " 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000',\n",
      " 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000',\n",
      " 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000',\n",
      " 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000',\n",
      " 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000',\n",
      " 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004',\n",
      " 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000',\n",
      " 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006',\n",
      " 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000',\n",
      " 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000',\n",
      " 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000',\n",
      " 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000',\n",
      " 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001',\n",
      " 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009',\n",
      " 'ef_000', 'eg_000']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "pprint(list(schema['Features'].keys()), compact = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001',\n",
      " 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009',\n",
      " 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000',\n",
      " 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000',\n",
      " 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007',\n",
      " 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005',\n",
      " 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003',\n",
      " 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000',\n",
      " 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000',\n",
      " 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000',\n",
      " 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000',\n",
      " 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000',\n",
      " 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004',\n",
      " 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000',\n",
      " 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006',\n",
      " 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000',\n",
      " 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000',\n",
      " 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000',\n",
      " 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000',\n",
      " 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001',\n",
      " 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009',\n",
      " 'ef_000', 'eg_000']\n"
     ]
    }
   ],
   "source": [
    "pprint(list(test_data.drop(columns = 'class').columns), compact = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa_000',\n",
       " 'ab_000',\n",
       " 'ac_000',\n",
       " 'ad_000',\n",
       " 'ae_000',\n",
       " 'af_000',\n",
       " 'ag_000',\n",
       " 'ag_001',\n",
       " 'ag_002',\n",
       " 'ag_003',\n",
       " 'ag_004',\n",
       " 'ag_005',\n",
       " 'ag_006',\n",
       " 'ag_007',\n",
       " 'ag_008',\n",
       " 'ag_009',\n",
       " 'ah_000',\n",
       " 'ai_000',\n",
       " 'aj_000',\n",
       " 'ak_000',\n",
       " 'al_000',\n",
       " 'am_0',\n",
       " 'an_000',\n",
       " 'ao_000',\n",
       " 'ap_000',\n",
       " 'aq_000',\n",
       " 'ar_000',\n",
       " 'as_000',\n",
       " 'at_000',\n",
       " 'au_000',\n",
       " 'av_000',\n",
       " 'ax_000',\n",
       " 'ay_000',\n",
       " 'ay_001',\n",
       " 'ay_002',\n",
       " 'ay_003',\n",
       " 'ay_004',\n",
       " 'ay_005',\n",
       " 'ay_006',\n",
       " 'ay_007',\n",
       " 'ay_008',\n",
       " 'ay_009',\n",
       " 'az_000',\n",
       " 'az_001',\n",
       " 'az_002',\n",
       " 'az_003',\n",
       " 'az_004',\n",
       " 'az_005',\n",
       " 'az_006',\n",
       " 'az_007',\n",
       " 'az_008',\n",
       " 'az_009',\n",
       " 'ba_000',\n",
       " 'ba_001',\n",
       " 'ba_002',\n",
       " 'ba_003',\n",
       " 'ba_004',\n",
       " 'ba_005',\n",
       " 'ba_006',\n",
       " 'ba_007',\n",
       " 'ba_008',\n",
       " 'ba_009',\n",
       " 'bb_000',\n",
       " 'bc_000',\n",
       " 'bd_000',\n",
       " 'be_000',\n",
       " 'bf_000',\n",
       " 'bg_000',\n",
       " 'bh_000',\n",
       " 'bi_000',\n",
       " 'bj_000',\n",
       " 'bk_000',\n",
       " 'bl_000',\n",
       " 'bm_000',\n",
       " 'bn_000',\n",
       " 'bo_000',\n",
       " 'bp_000',\n",
       " 'bq_000',\n",
       " 'br_000',\n",
       " 'bs_000',\n",
       " 'bt_000',\n",
       " 'bu_000',\n",
       " 'bv_000',\n",
       " 'bx_000',\n",
       " 'by_000',\n",
       " 'bz_000',\n",
       " 'ca_000',\n",
       " 'cb_000',\n",
       " 'cc_000',\n",
       " 'cd_000',\n",
       " 'ce_000',\n",
       " 'cf_000',\n",
       " 'cg_000',\n",
       " 'ch_000',\n",
       " 'ci_000',\n",
       " 'cj_000',\n",
       " 'ck_000',\n",
       " 'cl_000',\n",
       " 'cm_000',\n",
       " 'cn_000',\n",
       " 'cn_001',\n",
       " 'cn_002',\n",
       " 'cn_003',\n",
       " 'cn_004',\n",
       " 'cn_005',\n",
       " 'cn_006',\n",
       " 'cn_007',\n",
       " 'cn_008',\n",
       " 'cn_009',\n",
       " 'co_000',\n",
       " 'cp_000',\n",
       " 'cq_000',\n",
       " 'cr_000',\n",
       " 'cs_000',\n",
       " 'cs_001',\n",
       " 'cs_002',\n",
       " 'cs_003',\n",
       " 'cs_004',\n",
       " 'cs_005',\n",
       " 'cs_006',\n",
       " 'cs_007',\n",
       " 'cs_008',\n",
       " 'cs_009',\n",
       " 'ct_000',\n",
       " 'cu_000',\n",
       " 'cv_000',\n",
       " 'cx_000',\n",
       " 'cy_000',\n",
       " 'cz_000',\n",
       " 'da_000',\n",
       " 'db_000',\n",
       " 'dc_000',\n",
       " 'dd_000',\n",
       " 'de_000',\n",
       " 'df_000',\n",
       " 'dg_000',\n",
       " 'dh_000',\n",
       " 'di_000',\n",
       " 'dj_000',\n",
       " 'dk_000',\n",
       " 'dl_000',\n",
       " 'dm_000',\n",
       " 'dn_000',\n",
       " 'do_000',\n",
       " 'dp_000',\n",
       " 'dq_000',\n",
       " 'dr_000',\n",
       " 'ds_000',\n",
       " 'dt_000',\n",
       " 'du_000',\n",
       " 'dv_000',\n",
       " 'dx_000',\n",
       " 'dy_000',\n",
       " 'dz_000',\n",
       " 'ea_000',\n",
       " 'eb_000',\n",
       " 'ec_00',\n",
       " 'ed_000',\n",
       " 'ee_000',\n",
       " 'ee_001',\n",
       " 'ee_002',\n",
       " 'ee_003',\n",
       " 'ee_004',\n",
       " 'ee_006',\n",
       " 'ee_007',\n",
       " 'ee_008',\n",
       " 'ee_009',\n",
       " 'ef_000',\n",
       " 'eg_000']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_data.drop(columns = ['class','ee_005']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random_numbers = [random.randint(0, 1) for _ in range(50)]\n",
    "\n",
    "print(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random_numbers = np.array([random.randint(0, 1) for _ in range(50)])\n",
    "\n",
    "random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import eval_metrics\n",
    "\n",
    "y_test_random = np.array([random.randint(0, 1) for _ in range(50)])\n",
    "y_pred_random = np.array([random.randint(0, 1) for _ in range(50)])\n",
    "eval_dict = eval_metrics(y_test_random,y_pred_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Cost' in eval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Balanced_Accuracy_Score': 0.4230769230769231,\n",
       " 'F1_Score': 0.3829787234042554,\n",
       " 'Accuracy_Score': 0.42,\n",
       " 'Cost': 8620.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Balanced_Accuracy_Score', 'F1_Score', 'Accuracy_Score', 'Cost'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(key in eval_dict for key in ['Balanced_Accuracy_Score', 'F1_Score', 'Accuracy_Score', 'Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
