{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "import yaml\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, \n",
    "                              HistGradientBoostingClassifier, StackingClassifier, VotingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (balanced_accuracy_score, f1_score,\n",
    "                             accuracy_score, confusion_matrix)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.constants import *\n",
    "from src.utils import load_yaml\n",
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\Scania_Truck_Failures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Params.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 07:57:25,834: INFO: utils: params.yaml yaml_file is loaded]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigBox({'optuna': {'Logistic_Regression': {'penalty': \"trial.suggest_categorical('penalty', ['l2', None])\"}, 'SGD_Classifier': {'loss': \"trial.suggest_categorical('loss', ['squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_error', 'perceptron', 'squared_hinge', 'hinge', 'log_loss', 'modified_huber'])\"}, 'Random Forest': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\", 'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Ada_Boost': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\", 'algorithm': \"trial.suggest_categorical('algorithm', ['SAMME', 'SAMME.R'])\"}, 'Grad_Boost': {'loss': \"trial.suggest_categorical('loss', ['log_loss', 'exponential'])\", 'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\", 'criterion': \"trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\"}, 'Bagging_Classifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\"}, 'ExtraTreesClassifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\", 'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Hist_Grad_Boost_Classifier': {'max_iter': \"trial.suggest_int('max_iter', 100, 800)\"}, 'Decision_Tree_Classifier': {'criterion': \"trial.suggest_categorical('criterion', ['log_loss', 'entropy', 'gini'])\", 'splitter': \"trial.suggest_categorical('splitter', ['best', 'random'])\", 'max_features': \"trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\"}, 'XGB_Classifier': {'n_estimators': \"trial.suggest_int('n_estimators', 100, 1500)\", 'learning_rate': \"trial.suggest_float('learning_rate', .00001, 8.0)\", 'booster': \"trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart'])\", 'tree_method': \"trial.suggest_categorical('tree_method', ['exact', 'approx', 'hist'])\"}, 'KNN_Classifier': {'n_neighbors': \"trial.suggest_int('n_neighbors', 3, 11, step=2)\", 'weights': \"trial.suggest_categorical('weights', ['uniform', 'distance'])\", 'algorithm': \"trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\"}, 'MLP_Classifier': {'hidden_layer_sizes': \"trial.suggest_categorical('hidden_layer_sizes', [(500,), (500, 300, 200, 150,), (700, 500, 300, 100, ), (1500, 800, 400, 200, )])\", 'activation': \"trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh' , 'relu'])\", 'learning_rate': \"trial.suggest_categorical('learning_rate', ['constant', 'invscaling', 'adaptive'])\", 'max_iter': \"trial.suggest_int('max_iter', 100, 800)\"}, 'Stacked_Classifier': {'stack_method': \"trial.suggest_categorical('stack_method', ['auto', 'predict_proba', 'decision_function', 'predict'])\", 'passthrough': \"trial.suggest_categorical('stack_method', [True, False])\"}}, 'hyperopt': {'Logistic_Regression': {'penalty': \"hp.choice('penalty', ['l2', None])\"}, 'SGD_Classifier': {'loss': \"hp.choice('loss', ['squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_error', 'perceptron', 'squared_hinge', 'hinge', 'log_loss', 'modified_huber'])\"}, 'Random Forest': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1500, 1))\", 'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"hp.choice('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Ada_Boost': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1500, 1))\", 'algorithm': \"hp.choice('algorithm', ['SAMME', 'SAMME.R'])\"}, 'Grad_Boost': {'loss': \"hp.choice('loss', ['log_loss', 'exponential'])\", 'n_estimators': \"hp.qunifor,('n_estimators', 100, 1500)\", 'criterion': \"hp.choice('criterion', ['friedman_mse', 'squared_error'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\"}, 'Bagging_Classifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1500, 1))\"}, 'ExtraTreesClassifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1500, 1))\", 'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\", 'class_weight': \"hp.choice('class_weight', ['balanced', 'balanced_subsample'])\"}, 'Hist_Grad_Boost_Classifier': {'max_iter': \"scope.int(hp.quniform('max_iter', 100, 800, 1))\"}, 'Decision_Tree_Classifier': {'criterion': \"hp.choice('criterion', ['log_loss', 'entropy', 'gini'])\", 'splitter': \"hp.choice('splitter', ['best', 'random'])\", 'max_features': \"hp.choice('max_features', ['sqrt', 'log2', None])\"}, 'XGB_Classifier': {'n_estimators': \"scope.int(hp.quniform('n_estimators', 100, 1500, 1))\", 'learning_rate': \"hp.uniform('learning_rate', .00001, 8.0)\", 'booster': \"hp.choice('booster', ['gbtree', 'gblinear', 'dart'])\", 'tree_method': \"hp.choice('tree_method', ['exact', 'approx', 'hist'])\"}, 'KNN_Classifier': {'n_neighbors': \"scope.int(hp.quniform('n_neighbors', 3, 11, step=2))\", 'weights': \"hp.choice('weights', ['uniform', 'distance'])\", 'algorithm': \"hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\"}, 'MLP_Classifier': {'hidden_layer_sizes': \"hp.choice('hidden_layer_sizes', [(500,), (500, 300, 200, 150,), (700, 500, 300, 100, ), (1500, 800, 400, 200, )])\", 'activation': \"hp.choice('activation', ['identity', 'logistic', 'tanh' , 'relu'])\", 'learning_rate': \"hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive'])\", 'max_iter': \"scope.int(hp.quniform('max_iter', 100, 800, 1))\"}, 'Stacked_Classifier': {'stack_method': \"hp.choice('stack_method', ['auto', 'predict_proba', 'decision_function', 'predict'])\", 'passthrough': \"hp.choice('stack_method', [True, False])\"}}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_config = load_yaml(PARAMS_PATH)\n",
    "params_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(params_config.randomized_search_cv['Random Forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params.yaml', 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['optuna']['Logistic_Regression']\n",
    "space = {}\n",
    "for key,value in config['optuna']['Random Forest'].items():\n",
    "    space[key] = eval(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['optuna']['Logistic_Regression']['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(config['optuna']['Logistic_Regression'].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['optuna']['Logistic_Regression']['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1978, 171) (1970, 171)\n",
      "(1978, 170) (1970, 170) (1978,) (1970,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "train_df = pd.read_csv(\".//artifacts\\data\\processed\\stage_2_processing\\processed_train_data.csv\")\n",
    "test_df = pd.read_csv(\".//artifacts\\data\\processed\\stage_2_processing\\processed_test_data.csv\")\n",
    "\n",
    "x_train = train_df.drop(columns='class')\n",
    "y_train = train_df['class']\n",
    "x_test = test_df.drop(columns='class')\n",
    "y_test = test_df['class']\n",
    "print(train_df.shape,test_df.shape)\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 20:35:05,870] A new study created in memory with name: no-name-0b3f0a3a-3620-4de9-82f6-f20741e8947f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 20:35:06,223] Trial 0 finished with value: 0.4964467005076142 and parameters: {'penalty': None}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:06,429] Trial 1 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:06,638] Trial 2 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:06,909] Trial 3 finished with value: 0.4964467005076142 and parameters: {'penalty': None}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,114] Trial 4 finished with value: 0.4964467005076142 and parameters: {'penalty': None}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,303] Trial 5 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,393] Trial 6 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,491] Trial 7 finished with value: 0.4964467005076142 and parameters: {'penalty': None}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,784] Trial 8 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n",
      "[I 2024-01-12 20:35:07,943] Trial 9 finished with value: 0.49086294416243653 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.4964467005076142.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def objective(trial,train_x = x_train,test_x = x_test, y_train = y_train, y_test = y_test):\n",
    "  # train_x,test_x,y_train,y_test=train_test_split(data,target,test_size=0.20,random_state=25)\n",
    "  param= {list(config['optuna']['Logistic_Regression'].keys())[0] : eval(config['optuna']['Logistic_Regression']['penalty'])}\n",
    "    \n",
    "  log_reg=LogisticRegression(**param)\n",
    "  log_reg.fit(train_x,y_train)\n",
    "  y_predict=log_reg.predict(test_x)\n",
    "  accuracy_score_=accuracy_score(y_test,y_predict)\n",
    "  return accuracy_score_\n",
    "find_param=optuna.create_study(direction = \"maximize\")\n",
    "find_param.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_param.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': None}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "eval('find_param.best_trial.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': None}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_param.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_param.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll.base import scope\n",
    "import hyperopt\n",
    "a = scope.int(hp.quniform('n_estimators', 100, 2000, 1))\n",
    "\n",
    "print(hyperopt.pyll.stochastic.sample(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['hyperopt']['Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['hyperopt']['Random Forest'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "space = {}\n",
    "for key,value in config['hyperopt']['Random Forest'].items():\n",
    "    space[key] = eval(value)\n",
    "def objective(space):\n",
    "    hp_rand_forest = RandomForestClassifier(**space)\n",
    "    hp_rand_forest.fit(train_x,y_train)\n",
    "    y_pred = hp_rand_forest.predict(test_x)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "    cost = float((10*fp)+(500*fn))\n",
    "    return cost\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 10,\n",
    "            trials= trials)\n",
    "best_randf=space_eval(space,best)\n",
    "best_randf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.average_best_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_randf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {'n_estimators': 352,\n",
    " 'criterion': 'entropy',\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': 'balanced_subsample'}\n",
    "randf=RandomForestClassifier(**b)\n",
    "randf.fit(train_x,y_train)\n",
    "y_pred=randf.predict(test_x)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost = float((10*fp)+(500*fn))\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = XGBClassifier(njobs = -1)\n",
    "model_name = 'XGB_Classifier'\n",
    "params_config = load_yaml(PARAMS_PATH)\n",
    "\n",
    "# def cost_scorer(estimator, X, y):\n",
    "#     x_train_, x_test_, y_train_, y_test_ = train_test_split(X,y, random_state=8, test_size = 0.25)\n",
    "#     estimator.fit(x_train_,y_train_)\n",
    "#     y_pred = estimator.predict(x_test_)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_true=y_test_, y_pred=y_pred).ravel()\n",
    "#     cost = float((10*fp)+(500*fn))\n",
    "#     return cost\n",
    "\n",
    "params_grid = dict(params_config.randomized_search_cv[model_name])\n",
    "random_search_cv = RandomizedSearchCV(estimator = model,\n",
    "                                        param_distributions = params_grid,\n",
    "                                        n_iter = 5,\n",
    "                                        scoring = 'accuracy',\n",
    "                                        n_jobs = -1,\n",
    "                                        verbose = 3,\n",
    "                                        random_state = 8\n",
    "                                        )\n",
    "random_search_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**random_search_cv.best_params_)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost = float((10*fp)+(500*fn))\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the User Defined Function: hyper_parameter_tuning()\n",
    "This is done to call optuna and hyperopt at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 00:03:35,963: INFO: utils: params.yaml yaml_file is loaded]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 00:03:35,966] A new study created in memory with name: no-name-3a2364cf-7cfe-4ace-bff1-9ec28564898f\n",
      "[I 2024-01-12 00:03:36,029] Trial 0 finished with value: 279830.0 and parameters: {'loss': 'modified_huber'}. Best is trial 0 with value: 279830.0.\n",
      "[I 2024-01-12 00:03:36,058] Trial 1 finished with value: 189640.0 and parameters: {'loss': 'squared_hinge'}. Best is trial 1 with value: 189640.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-12 00:03:36,111] Trial 2 finished with value: 225500.0 and parameters: {'loss': 'log_loss'}. Best is trial 1 with value: 189640.0.\n",
      "[I 2024-01-12 00:03:36,161] Trial 3 finished with value: 167180.0 and parameters: {'loss': 'epsilon_insensitive'}. Best is trial 3 with value: 167180.0.\n",
      "[I 2024-01-12 00:03:36,231] Trial 4 finished with value: 147690.0 and parameters: {'loss': 'squared_error'}. Best is trial 4 with value: 147690.0.\n",
      "[I 2024-01-12 00:03:36,383] Trial 5 finished with value: 109750.0 and parameters: {'loss': 'squared_epsilon_insensitive'}. Best is trial 5 with value: 109750.0.\n",
      "[I 2024-01-12 00:03:36,410] Trial 6 finished with value: 16960.0 and parameters: {'loss': 'squared_hinge'}. Best is trial 6 with value: 16960.0.\n",
      "[I 2024-01-12 00:03:36,448] Trial 7 finished with value: 128870.0 and parameters: {'loss': 'perceptron'}. Best is trial 6 with value: 16960.0.\n",
      "[I 2024-01-12 00:03:36,536] Trial 8 finished with value: 439620.0 and parameters: {'loss': 'squared_error'}. Best is trial 6 with value: 16960.0.\n",
      "[I 2024-01-12 00:03:36,581] Trial 9 finished with value: 407900.0 and parameters: {'loss': 'huber'}. Best is trial 6 with value: 16960.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna: SGD_Classifier --- {'cost': 16960.0, 'params': {'loss': 'squared_hinge'}}\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?][2024-01-12 00:03:36,597: INFO: tpe: build_posterior_wrapper took 0.003051 seconds]\n",
      "[2024-01-12 00:03:36,599: INFO: tpe: TPE using 0 trials]\n",
      "[2024-01-12 00:03:36,668: INFO: tpe: build_posterior_wrapper took 0.000998 seconds]\n",
      "[2024-01-12 00:03:36,671: INFO: tpe: TPE using 1/1 trials with best loss 310900.000000]\n",
      " 20%|██        | 2/10 [00:00<00:00,  9.92trial/s, best loss: 310900.0][2024-01-12 00:03:36,799: INFO: tpe: build_posterior_wrapper took 0.001052 seconds]\n",
      "[2024-01-12 00:03:36,801: INFO: tpe: TPE using 2/2 trials with best loss 310900.000000]\n",
      " 30%|███       | 3/10 [00:00<00:00,  9.12trial/s, best loss: 289000.0][2024-01-12 00:03:36,919: INFO: tpe: build_posterior_wrapper took 0.000000 seconds]\n",
      "[2024-01-12 00:03:36,922: INFO: tpe: TPE using 3/3 trials with best loss 289000.000000]\n",
      "[2024-01-12 00:03:36,980: INFO: tpe: build_posterior_wrapper took 0.000000 seconds]\n",
      "[2024-01-12 00:03:36,981: INFO: tpe: TPE using 4/4 trials with best loss 289000.000000]\n",
      " 50%|█████     | 5/10 [00:00<00:00, 12.48trial/s, best loss: 238880.0][2024-01-12 00:03:37,030: INFO: tpe: build_posterior_wrapper took 0.000000 seconds]\n",
      "[2024-01-12 00:03:37,032: INFO: tpe: TPE using 5/5 trials with best loss 238880.000000]\n",
      "[2024-01-12 00:03:37,055: INFO: tpe: build_posterior_wrapper took 0.000999 seconds]\n",
      "[2024-01-12 00:03:37,058: INFO: tpe: TPE using 6/6 trials with best loss 238880.000000]\n",
      "[2024-01-12 00:03:37,104: INFO: tpe: build_posterior_wrapper took 0.000972 seconds]\n",
      "[2024-01-12 00:03:37,107: INFO: tpe: TPE using 7/7 trials with best loss 238880.000000]\n",
      " 80%|████████  | 8/10 [00:00<00:00, 17.40trial/s, best loss: 238880.0][2024-01-12 00:03:37,146: INFO: tpe: build_posterior_wrapper took 0.000980 seconds]\n",
      "[2024-01-12 00:03:37,147: INFO: tpe: TPE using 8/8 trials with best loss 238880.000000]\n",
      "[2024-01-12 00:03:37,184: INFO: tpe: build_posterior_wrapper took 0.000027 seconds]\n",
      "[2024-01-12 00:03:37,185: INFO: tpe: TPE using 9/9 trials with best loss 127890.000000]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.47trial/s, best loss: 127890.0]\n",
      "HyperOpt: SGD_Classifier --- {'cost': 127890.0, 'params': {'loss': 'log_loss'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import parameter_tuning\n",
    "report = parameter_tuning(model_class = SGDClassifier,\n",
    "                          model_name = 'SGD_Classifier',\n",
    "                          x_train = x_train,\n",
    "                          x_test = x_test,\n",
    "                          y_train = y_train,\n",
    "                          y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optuna': {'cost': 16960.0, 'params': {'loss': 'squared_hinge'}},\n",
       " 'HyperOpt': {'cost': 127890.0, 'params': {'loss': 'log_loss'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Cost': 437200.0}, 'SGD_Classifier': {'Optuna': {'cost': 31760.0, 'params': {'loss': 'squared_error'}}, 'HyperOpt': {'cost': 4840.0, 'params': {'loss': 'squared_error'}}, 'Best_Params': {'loss': 'squared_error'}, 'Cost': 4840.0}}\n",
    "costs = [value['Cost'] for value in report.values()]\n",
    "min_cost = min(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Cost': 437200.0}, {'Optuna': {'cost': 31760.0, 'params': {'loss': 'squared_error'}}, 'HyperOpt': {'cost': 4840.0, 'params': {'loss': 'squared_error'}}, 'Best_Params': {'loss': 'squared_error'}, 'Cost': 4840.0}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4840.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = min(report['Optuna']['cost'],report['HyperOpt']['cost'])\n",
    "if min_value == report['Optuna']['cost']:\n",
    "    params = report['Optuna']['params']\n",
    "else:\n",
    "    params = report['HyperOpt']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16960.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'squared_hinge'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Best_Cost': 437200.0}, 'SGD_Classifier': {'Optuna': {'cost': 125050.0, 'params': {'loss': 'log_loss'}}, 'HyperOpt': \n",
    "{'cost': 15060.0, 'params': {'loss': 'hinge'}}, 'Best_Params': {'loss': 'hinge'}, 'Best_Cost': 15060.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic_Regression': {'Optuna': {'cost': 437200.0,\n",
       "   'params': {'penalty': None}},\n",
       "  'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}},\n",
       "  'Best_Params': {'penalty': None},\n",
       "  'Best_Cost': 437200.0},\n",
       " 'SGD_Classifier': {'Optuna': {'cost': 125050.0,\n",
       "   'params': {'loss': 'log_loss'}},\n",
       "  'HyperOpt': {'cost': 15060.0, 'params': {'loss': 'hinge'}},\n",
       "  'Best_Params': {'loss': 'hinge'},\n",
       "  'Best_Cost': 15060.0}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15060.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary['SGD_Classifier'].keys()\n",
    "costs = [value['Best_Cost'] for value in dictionary.values()]\n",
    "min_cost = min(costs)\n",
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'hinge'}\n",
      "('SGD_Classifier', 15060.0, {'loss': 'hinge'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Logistic_Regression': LogisticRegression(), \n",
    "            'SGD_Classifier': SGDClassifier(),\n",
    "            'Random Forest': RandomForestClassifier, \n",
    "            'Ada_Boost': AdaBoostClassifier, \n",
    "            'Grad_Boost': GradientBoostingClassifier, \n",
    "            'Bagging_Classifier': BaggingClassifier, \n",
    "            'ExtraTreesClassifier': ExtraTreesClassifier, \n",
    "            'Hist_Grad_Boost_Classifier': HistGradientBoostingClassifier, \n",
    "            'Decision_Tree_Classifier': DecisionTreeClassifier,\n",
    "            'XGB_Classifier': XGBClassifier,\n",
    "            'KNN_Classifier': KNeighborsClassifier,\n",
    "            'MLP_Classifier': MLPClassifier\n",
    "            }\n",
    "for i in dictionary.keys():\n",
    "    if min_cost == dictionary[i]['Best_Cost']:\n",
    "        best_params_so_far = dictionary[i]['Best_Params']\n",
    "print(best_params_so_far)\n",
    "\n",
    "\n",
    "##Same code as a list comprehension\n",
    "best_params_so_far_ = [(i, min_cost, dictionary[i]['Best_Params']) for i in dictionary.keys() if min_cost == dictionary[i]['Best_Cost']]\n",
    "print(best_params_so_far_[0])\n",
    "\n",
    "model = models[best_params_so_far_[0][0]]\n",
    "model(**best_params_so_far_[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fetching the dataframe of 1st five best models for Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_ = sorted(dictionary.items(), key = lambda x: x[1]['Best_Cost'])[:5]\n",
    "best_models = [best_models_[i][0] for i in range(len(best_models_))]\n",
    "best_models_with_params = []\n",
    "for i in best_models:\n",
    "    best_models_with_params.append((i,dictionary[i]['Best_Params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SGD_Classifier', {'loss': 'hinge'}),\n",
       " ('Logistic_Regression', {'penalty': None})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logistic_Regression'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_with_params[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SGD_Classifier'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_with_params[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SGD_Classifier', SGDClassifier()),\n",
       " ('Logistic_Regression', LogisticRegression(penalty=None))]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators = {}\n",
    "for i in range(len(best_models_with_params)):\n",
    "    best_estimators[best_models_with_params[i][0]] = models[best_models_with_params[i][0]](**best_models_with_params[i][1])\n",
    "best_estimators = list(zip(best_estimators.keys(),best_estimators.values()))\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(penalty=None).get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': None,\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators[1][1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SGD_Classifier', {'loss': 'hinge'}),\n",
       " ('Logistic_Regression', {'penalty': None})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict = {}\n",
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'Logistic_Regression': {'Optuna': {'cost': 437200.0, 'params': {'penalty': None}}, 'HyperOpt': {'cost': 437200.0, 'params': {'penalty': None}}, 'Best_Params': {'penalty': None}, 'Best_Cost': 437200.0}}\n",
    "my_dict.values()\n",
    "# [value['Best_Cost'] for value in my_dict.values()]\n",
    "for i in my_dict.values():\n",
    "    value = i['Best_Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437200.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437200.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i['Best_Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('KNN_Classifier', 90240.0, {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute'})][0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config_Manager - Sorting Report Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.configuration_manager import ConfigurationManager\n",
    "obj = ConfigurationManager()\n",
    "preprocessor_config = obj.get_preprocessor_config()\n",
    "os.listdir(preprocessor_config.root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(preprocessor_config.preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics['name'] = 'LogisticRegression()'\n",
    "metrics['b_score'] = 9999999999.32\n",
    "metrics['a_score'] = 3.23\n",
    "\n",
    "report = {}\n",
    "report['log_reg'] = metrics\n",
    "\n",
    "metrics_a={}\n",
    "metrics_a['name'] = 'SVC()'\n",
    "metrics_a['b_score'] = 9934\n",
    "metrics_a['a_score'] = 23534.23\n",
    "\n",
    "report['svm'] = metrics_a\n",
    "\n",
    "name = max(report.keys(), key = lambda k: report[k].get('a_score', 0))\n",
    "report[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_yaml,load_binary\n",
    "\n",
    "model_dict = load_yaml(filepath = Path('artifacts\\metrics\\metrics.yaml'))\n",
    "\n",
    "model = load_binary(filepath = Path('artifacts\\model\\model.joblib'))\n",
    "\n",
    "preprocessor = load_binary(filepath = Path('artifacts\\preprocessor\\preprocessor.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')\n",
    "X = df.drop(columns = 'class').iloc[:1000,:]\n",
    "y = df['class'].iloc[:1000]\n",
    "X_transformed = preprocessor.transform(X = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_transformed).isna().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "smote = SMOTETomek(sampling_strategy = 'minority',\n",
    "                   random_state = 8,\n",
    "                   n_jobs = -1)\n",
    "\n",
    "x_smote, y_smote = smote.fit_resample(X = X_transformed,\n",
    "                                      y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (balanced_accuracy_score, f1_score,\n",
    "                             accuracy_score, confusion_matrix)\n",
    "\n",
    "y_pred = model.predict(x_smote)\n",
    "balanced_accuracy_score_ = float(balanced_accuracy_score(y_true=y_smote, y_pred=y_pred))\n",
    "f1_score_ = float(f1_score(y_true=y_smote, y_pred=y_pred))\n",
    "accuracy_score_ = float(accuracy_score(y_true=y_smote, y_pred=y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_smote, y_pred=y_pred).ravel()\n",
    "cost_ = float((10*fp)+(500*fn))\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_}')\n",
    "print(f'accuracy_score_: {accuracy_score_}')\n",
    "print(f'f1_score_: {f1_score_}')\n",
    "print(f'cost_: {cost_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT.predict(x_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import save_yaml\n",
    "save_yaml(file=report,filepath='f:\\iNeuron\\Projects\\Scania_Truck_Failures\\sample.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('f:\\\\iNeuron\\\\Projects\\\\Scania_Truck_Failures')\n",
    "with open (Path('.\\\\config\\\\config.yaml')) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print({list(config['data_ingestion_config']['test_data3'].keys())[0]:list(config['data_ingestion_config']['test_data3'].values())[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['data_ingestion_config']['test_data3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(os.listdir('../notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('F:\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['class'] = df1['class'].map({'neg':0,'pos':1})\n",
    "df1.replace('na',np.nan,inplace=True)\n",
    "col_list = [i for i in df1.columns if i != 'class']\n",
    "for i in col_list:\n",
    "    df1[i]=df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = df1.drop(columns = 'class').describe()==df.drop(columns='class').describe()\n",
    "for i in check_df.columns:\n",
    "    print(i,check_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = pd.read_csv('F:\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_test_set.csv')\n",
    "test_df1['class'] = test_df1['class'].map({'neg':0,'pos':1})\n",
    "test_df1.replace('na',np.nan,inplace=True)\n",
    "col_list = [i for i in test_df1.columns if i != 'class']\n",
    "for i in col_list:\n",
    "    test_df1[i]=test_df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check_df = test_df.drop(columns = 'class').describe()==test_df1.drop(columns='class').describe()\n",
    "for i in test_check_df.columns:\n",
    "    print(i,test_check_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ci_000'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"artifacts\\data\\processed\\stage_2_processing\\processed_train_data.csv\").iloc[:1000,:]\n",
    "test_df = pd.read_csv(\"artifacts\\data\\processed\\stage_2_processing\\processed_test_data.csv\").iloc[:1000,:]\n",
    "\n",
    "x_train = train_df.drop(columns = 'class')\n",
    "y_train = train_df['class']\n",
    "x_test = test_df.drop(columns = 'class')\n",
    "y_test = test_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic_Regression': LogisticRegression(), \n",
    "        'SGD_Classifier': SGDClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(), \n",
    "        'Ada_Boost': AdaBoostClassifier(), \n",
    "        'Grad_Boost': GradientBoostingClassifier(), \n",
    "        'Bagging_Classifier': BaggingClassifier(), \n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(), \n",
    "        'Hist_Grad_Boost_Classifier': HistGradientBoostingClassifier(), \n",
    "        'Decision_Tree_Classifier': DecisionTreeClassifier(),\n",
    "        'XGB_Classifier': XGBClassifier(),\n",
    "        'KNN_Classifier': KNeighborsClassifier(),\n",
    "        'MLP_Classifier': MLPClassifier()\n",
    "        }\n",
    "report = {}\n",
    "# metrics_list = ['balanced_accuracy_score','f1_score','accuracy_score']\n",
    "for model_name,model in models.items():\n",
    "        print(model_name)\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        metrics = {}\n",
    "        metrics['balanced_accuracy_score'] = float(balanced_accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        metrics['f1_score'] = float(f1_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        metrics['accuracy_score'] = float(accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "        metrics['cost'] = float((10*fp)+(500*fn))\n",
    "\n",
    "        print(metrics,'\\n')\n",
    "\n",
    "        report[model_name] = metrics\n",
    "\n",
    "best_model_name_by_cost = min(report.keys(), key = lambda k: report[k].get('cost', 0))\n",
    "print(\"\\nBest Model:\")\n",
    "print(models[best_model_name_by_cost])\n",
    "print(report[best_model_name_by_cost],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.sort_values(by ='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = sorted(report.items(), key=lambda x: x[1]['cost'])[:5]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_names_ = [best_models[i][0] for i in range(len(best_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators = {}\n",
    "for i in best_models_names_:\n",
    "    best_estimators[i] = models[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators_copy = best_estimators.copy()\n",
    "best_estimators_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators_copy = list(zip(best_estimators_copy.keys(),best_estimators_copy.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_classifier = StackingClassifier(estimators = best_estimators_copy,\n",
    "                                        final_estimator =  AdaBoostClassifier(),\n",
    "                                        cv = 5,\n",
    "                                        n_jobs = -1,\n",
    "                                        passthrough = False,\n",
    "                                        verbose = 3)\n",
    "\n",
    "stacked_classifier.fit(x_train,y_train)\n",
    "y_pred = stacked_classifier.predict(x_test)\n",
    "\n",
    "balanced_accuracy_score_ = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1_score_= f1_score(y_true=y_test, y_pred=y_pred)\n",
    "accuracy_score_ = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost_ = (10*fp)+(500*fn)\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_}')\n",
    "print(f'f1_score_: {f1_score_}')\n",
    "print(f'accuracy_score_: {accuracy_score_}')\n",
    "print(f'cost_: {cost_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier_ = VotingClassifier(estimators = best_estimators_copy,\n",
    "                                      voting = \"soft\",\n",
    "                                    weights = None,\n",
    "                                    n_jobs = -1,\n",
    "                                    verbose = True)\n",
    "voting_classifier_.fit(x_train,y_train)\n",
    "y_pred = voting_classifier_.predict(x_test)\n",
    "\n",
    "balanced_accuracy_score_voting = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1_score_voting= f1_score(y_true=y_test, y_pred=y_pred)\n",
    "accuracy_score_voting = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "cost_voting = (10*fp)+(500*fn)\n",
    "\n",
    "print(f'balanced_accuracy_score_: {balanced_accuracy_score_voting}')\n",
    "print(f'f1_score_: {f1_score_voting}')\n",
    "print(f'accuracy_score_: {accuracy_score_voting}')\n",
    "print(f'cost_: {cost_voting}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('F:\\\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace('na',np.nan,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns = 'class').isna().sum() == df.drop(columns = 'class').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = df1.drop(columns = 'class').columns.tolist()\n",
    "for i in cols_list:\n",
    "    df1[i] = df1[i].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df1 = df1.drop(columns = 'class').describe() == df.drop(columns = 'class').describe()\n",
    "for i in check_df1.columns:\n",
    "    print(i, check_df1[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('.\\\\artifacts\\data\\processed\\stage_1_processing\\preprocessed_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('F:\\\\iNeuron\\Projects\\Data\\Scania Truck Failures\\\\aps_failure_training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.replace('na',np.nan,inplace = True)\n",
    "test_col_list = [i for i in df3.columns if i != 'class']\n",
    "for i in test_col_list:\n",
    "    df3[i]=df3[i].astype('float')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df3.drop(columns = 'class').isna().sum() == df2.drop(columns = 'class').isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df2 = df3.drop(columns = 'class').describe() == df2.drop(columns = 'class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in check_df2.columns:\n",
    "    print(i, check_df2[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
